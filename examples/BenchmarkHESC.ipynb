{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee63aa7-80a0-4a0b-b172-12638a7b48c6",
   "metadata": {},
   "source": [
    "# Benchmark in hESC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3617db-6347-4c3f-abf3-b219b98de673",
   "metadata": {},
   "source": [
    "The data is from 'Single-cell RNA-seq reveals novel regulators of human embryonic stem cell differentiation to definitive endoderm', but data is downloaded from beeline https://zenodo.org/records/3701939"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416fed5-266c-4422-953c-7eb226dc8864",
   "metadata": {},
   "source": [
    "## Import libraries and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b871b19-b98c-4358-a488-e5731dd3e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "import subprocess\n",
    "\n",
    "BASE_DIR = '/sibcb1/chenluonanlab8/caideyu/CauTrigger_new/'\n",
    "case_path = os.path.join(BASE_DIR, 'BenchmarkHESC/')\n",
    "data_path = os.path.join(case_path, 'data/')\n",
    "output_path = os.path.join(case_path, 'output_test/')\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd505f-58cf-485c-b5fb-4c1a5d8c931f",
   "metadata": {},
   "source": [
    "## pySCENIC method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d62a5-40f4-4e04-8032-82fa26788f99",
   "metadata": {},
   "source": [
    "please prepare or install pySCENIC and download resources from pySCENIC (https://resources.aertslab.org/cistarget/databases/), and replace 'pyscenic' below in step 1 and 2-3 after '!' with your own pyscenic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e09fbddf-d01b-4820-b085-f6f9b436cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenic(data_path, output_path, seed=-1):\n",
    "    import subprocess\n",
    "    from pyscenic.utils import load_motifs\n",
    "    from pyscenic.aucell import aucell\n",
    "    from pyscenic.rss import regulon_specificity_scores\n",
    "    from pyscenic.cli.utils import load_signatures\n",
    "    RESOURCES_FOLDERNAME = data_path\n",
    "    RESULTS_FOLDERNAME = output_path\n",
    "    FIGURES_FOLDERNAME = output_path\n",
    "    AUXILLIARIES_FOLDERNAME = data_path\n",
    "    DATASET_ID = 'hESC'\n",
    "    RANKING_DBS_FNAMES = list(map(lambda fn: os.path.join(AUXILLIARIES_FOLDERNAME, fn),\n",
    "                       ['hg19-500bp-upstream-7species.mc9nr.genes_vs_motifs.rankings.feather',\n",
    "                       'hg19-500bp-upstream-10species.mc9nr.genes_vs_motifs.rankings.feather',\n",
    "                       'hg19-tss-centered-10kb-10species.mc9nr.genes_vs_motifs.rankings.feather',\n",
    "                       'hg19-tss-centered-10kb-7species.mc9nr.genes_vs_motifs.rankings.feather',\n",
    "                       'hg19-tss-centered-5kb-10species.mc9nr.genes_vs_motifs.rankings.feather',\n",
    "                        'hg19-tss-centered-5kb-7species.mc9nr.genes_vs_motifs.rankings.feather']))\n",
    "    MOTIF_ANNOTATIONS_FNAME = os.path.join(RESOURCES_FOLDERNAME, 'motifs-v9-nr.hgnc-m0.001-o0.0.tbl')\n",
    "    MM_TFS_FNAME = os.path.join(RESULTS_FOLDERNAME, 'hg_tfs.txt')\n",
    "    COUNTS_QC_MTX_FNAME = os.path.join(RESULTS_FOLDERNAME, f'{DATASET_ID}.qc.counts.csv')\n",
    "    ADJACENCIES_FNAME = os.path.join(RESULTS_FOLDERNAME, f'{DATASET_ID}.adjacencies.tsv')\n",
    "    MOTIFS_FNAME = os.path.join(RESULTS_FOLDERNAME, f'{DATASET_ID}.motifs.csv')\n",
    "    pd_motifs = pd.read_csv(MOTIF_ANNOTATIONS_FNAME, sep='\\t')\n",
    "    mm_tfs = pd_motifs.gene_name.unique()\n",
    "    with open(MM_TFS_FNAME, 'wt') as f:\n",
    "        f.write('\\n'.join(mm_tfs) + '\\n')\n",
    "    expData = pd.read_csv(data_path+'hESC_ExpressionData.csv', index_col=0).transpose()\n",
    "    adata = sc.AnnData(X=expData, dtype=np.float32)\n",
    "    adata.obs['cell_type'] = 'RSS'\n",
    "    sc.pp.filter_cells(adata, min_genes=200)\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    # STEP 1: Network inference based on GRNBoost2 from CLI\n",
    "    df_counts_qc = adata.to_df()\n",
    "    df_counts_qc.to_csv(COUNTS_QC_MTX_FNAME)\n",
    "    command = f\"~/miniconda3/envs/Project_CT/bin/pyscenic grn {COUNTS_QC_MTX_FNAME} {MM_TFS_FNAME} -o {ADJACENCIES_FNAME} --num_workers 6\"\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "    # STEP 2-3: Regulon prediction aka cisTarget from CLI\n",
    "    DBS_PARAM = ' '.join(RANKING_DBS_FNAMES)\n",
    "    # !~/miniconda3/envs/Project_CT/bin/pyscenic ctx {ADJACENCIES_FNAME} {DBS_PARAM} --annotations_fname {MOTIF_ANNOTATIONS_FNAME} --expression_mtx_fname {COUNTS_QC_MTX_FNAME} --output {MOTIFS_FNAME} --num_workers 32\n",
    "    command = f\"~/miniconda3/envs/Project_CT/bin/pyscenic ctx {ADJACENCIES_FNAME} {DBS_PARAM} --annotations_fname {MOTIF_ANNOTATIONS_FNAME} --expression_mtx_fname {COUNTS_QC_MTX_FNAME} --output {MOTIFS_FNAME} --num_workers 6\"\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "    # STEP 4: Cellular enrichment aka AUCell\n",
    "    sig = load_signatures(MOTIFS_FNAME)\n",
    "    auc_mtx = aucell(df_counts_qc, sig, num_workers=1)\n",
    "    rss = regulon_specificity_scores(auc_mtx, adata.obs.cell_type)\n",
    "    df = rss.transpose()\n",
    "    df.rename(index=lambda x: x.replace(\"(+)\", \"\"), inplace=True)\n",
    "    df = pd.DataFrame(df).sort_values(by='RSS', ascending=False)\n",
    "    print(f'{seed} done!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cefc9e-553c-4539-8ff9-606bbb63d8c2",
   "metadata": {},
   "source": [
    "## CEFCON method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8a089-272f-4a33-8786-51bfe0544418",
   "metadata": {},
   "source": [
    "CEFCON needs NichNet as input, please download from https://github.com/saeyslab/nichenetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3e10616-241b-4e35-8328-6429c7fe1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cefcon(data_path, output_path, seed=-1):\n",
    "    import cefcon as cf\n",
    "    expData = pd.read_csv(os.path.join(data_path, 'hESC_ExpressionData.csv'), index_col=0).transpose()\n",
    "    pseudotime = pd.read_csv(os.path.join(data_path, 'hESC_PseudoTime.csv'), index_col=0)\n",
    "    logFC = pd.read_csv(os.path.join(data_path, 'hESC_DEgenes_MAST_hvg1000_sp4.csv'), index_col=0)\n",
    "    network_data = pd.read_csv(os.path.join(data_path, 'NicheNet_human.csv'), index_col=None, header=0)\n",
    "    adata = sc.AnnData(X=expData, dtype=np.float32)\n",
    "    adata.layers['log_transformed'] = adata.X.copy()\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=1000)\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    adata.obs['all_pseudotime'] = pseudotime['PseudoTime']\n",
    "    logFC.rename(columns={'logFC': 'all_logFC'}, inplace=True)\n",
    "    adata.var = pd.merge(adata.var, logFC, left_index=True, right_index=True, how='left')\n",
    "    data = cf.data_preparation(input_expData=adata, input_priorNet=network_data)\n",
    "    cefcon_results_dict = {}\n",
    "    for li, data_li in data.items():\n",
    "        cefcon_GRN_model = cf.NetModel(epochs=350, repeats=1, cuda='0', seed=seed)\n",
    "        cefcon_GRN_model.run(data_li)\n",
    "        cefcon_results = cefcon_GRN_model.get_cefcon_results(edge_threshold_avgDegree=8)\n",
    "        cefcon_results_dict[li] = cefcon_results\n",
    "    for li, result_li in cefcon_results_dict.items():\n",
    "        print(f'Lineage - {li}:')\n",
    "        result_li.gene_influence_score()\n",
    "        result_li.driver_regulators()\n",
    "    result_all = cefcon_results_dict['all']\n",
    "    gene_info_df = result_all.driver_regulator.sort_values(by='influence_score', ascending=False)\n",
    "    return gene_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a78bf9-7461-4ae3-b6c1-2ed1eb94d6bb",
   "metadata": {},
   "source": [
    "## CellOracle method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3d0f0887-1f0d-47bb-b580-81f2dbf4156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_celloracle(data_path, output_path, seed=-1):\n",
    "    import celloracle as co\n",
    "    expData = pd.read_csv(os.path.join(data_path, 'hESC_ExpressionData.csv'), index_col=0).transpose()\n",
    "    base_GRN = co.data.load_human_promoter_base_GRN()\n",
    "    adata = sc.AnnData(X=expData, dtype=np.float32)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=1000)\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    sc.tl.pca(adata)\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, n_pcs=35)\n",
    "    sc.tl.leiden(adata, resolution=0.7)\n",
    "    adata.obs['manual_cluster'] = '0'\n",
    "    adata.layers['raw_count'] = adata.X.copy()\n",
    "    oracle = co.Oracle()\n",
    "    oracle.import_anndata_as_normalized_count(adata=adata, cluster_column_name=\"manual_cluster\", embedding_name=\"X_pca\")\n",
    "    oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "    oracle.perform_PCA()\n",
    "    n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0]\n",
    "    n_comps = min(n_comps, 50)\n",
    "    n_cell = oracle.adata.shape[0]\n",
    "    k = int(0.025*n_cell)\n",
    "    oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8, b_maxl=k*4, n_jobs=4)\n",
    "    links = oracle.get_links(cluster_name_for_GRN_unit=\"manual_cluster\", alpha=10, verbose_level=10, model_method='bayesian_ridge')\n",
    "    links.filter_links(p=0.001, weight=\"coef_abs\", threshold_number=2000)\n",
    "    links.get_network_score()\n",
    "    gene_info_df = pd.DataFrame(links.merged_score['degree_centrality_all'].sort_values(ascending=False))\n",
    "    return gene_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35162ea9-f863-4a78-9d47-973d3d135303",
   "metadata": {},
   "source": [
    "## Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b3abea2-462a-4a31-a366-5c23ed591ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cautrigger(data_path, output_path, seed=-1):\n",
    "    from CauTrigger.utils import set_seed\n",
    "    from CauTrigger.model import CauTrigger2L, CauTrigger3L\n",
    "    import anndata\n",
    "    expData = pd.read_csv(os.path.join(data_path, 'hESC_ExpressionData.csv'), index_col=0).transpose()\n",
    "    adata = sc.AnnData(X=expData, dtype=np.float32)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor='cell_ranger')\n",
    "    hESC = adata[:, adata.var.highly_variable]\n",
    "    Trrust = pd.read_table(os.path.join(data_path, 'trrust_rawdata.human.tsv'), header=None)\n",
    "    Trrust_TF = Trrust.iloc[:, 0].dropna().unique()\n",
    "    Trrust_nonTF = np.setdiff1d(Trrust.iloc[:, 1].dropna().unique(), Trrust_TF)\n",
    "    hESC_pt = pd.read_csv(os.path.join(data_path, 'hESC_PseudoTime.csv'), index_col=0)\n",
    "    hESC_pt['cell_type_1'] = np.where(hESC_pt.index.str.contains('00h'), 0, np.where(hESC_pt.index.str.contains('96h'), 1, np.nan))\n",
    "    hESC_deg = pd.read_csv(os.path.join(data_path, 'hESC_DEgenes_MAST_hvg1000_sp4.csv'), index_col=0)\n",
    "    hESC.obs = hESC_pt\n",
    "    start_TF = hESC[(hESC.obs['cell_type_1'] == 0), np.intersect1d(hESC.var_names, Trrust_TF)]\n",
    "    end_TF = hESC[(hESC.obs['cell_type_1'] == 1), np.intersect1d(hESC.var_names, Trrust_TF)]\n",
    "    start_down = hESC[(hESC.obs['cell_type_1'] == 0), np.intersect1d(hESC.var_names, Trrust_nonTF)]\n",
    "    end_down = hESC[(hESC.obs['cell_type_1'] == 1), np.intersect1d(hESC.var_names, Trrust_nonTF)]\n",
    "    adata = anndata.concat([start_TF.copy(), end_TF.copy()])\n",
    "    adata.obs['labels'] = np.repeat([0, 1], [start_TF.shape[0], end_TF.shape[0]])\n",
    "    adata.obsm['X_down'] = anndata.concat([start_down, end_down]).X.copy()\n",
    "    init_weight = pd.DataFrame({'gene':adata.var_names})\n",
    "    mESC_deg1 = hESC_deg.copy()\n",
    "    mESC_deg1['gene'] = mESC_deg1.index\n",
    "    init_weight1 = pd.merge(init_weight, mESC_deg1, on='gene', how='left')\n",
    "    min_value = init_weight1['logFC'].min()\n",
    "    max_value = init_weight1['logFC'].max()\n",
    "    init_weight1['logFC'] = init_weight1['logFC'].apply(lambda x: (x - min_value) / (max_value - min_value) * 0.5 + 0.5 if pd.notnull(x) else x)\n",
    "    init_weight1['logFC'] = init_weight1['logFC'].fillna(0.5)\n",
    "    prior_probs = np.array(init_weight1['logFC'])\n",
    "    set_seed(seed)\n",
    "    model = CauTrigger2L(\n",
    "            adata,\n",
    "            n_causal=2,\n",
    "            n_latent=10,\n",
    "            n_hidden=256,\n",
    "            n_layers_encoder=1,\n",
    "            n_layers_decoder=1,\n",
    "            n_layers_dpd=1,\n",
    "            dropout_rate_encoder=0.5,\n",
    "            dropout_rate_decoder=0.5,\n",
    "            dropout_rate_dpd=0.5,\n",
    "            use_batch_norm='none',\n",
    "            use_batch_norm_dpd=True,\n",
    "            decoder_linear=True,\n",
    "            dpd_linear=False,\n",
    "            init_weight=None,\n",
    "            init_thresh=0.0,\n",
    "            update_down_weight=False,\n",
    "            attention=True,\n",
    "            att_mean=False,\n",
    "        )\n",
    "    model.pretrain_attention(prior_probs=prior_probs, max_epochs=100)\n",
    "    model.train(max_epochs=500, stage_training=True, im_factor=1)\n",
    "    weight_df = model.get_up_feature_weights(normalize=True, method=\"Model\", sort_by_weight=False)[0]\n",
    "    model_res = pd.DataFrame({'weight_value': weight_df['weight'], }).sort_values('weight_value', ascending=False)\n",
    "    return model_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba81d8-81dd-4e93-ad63-a4c8dcd1f476",
   "metadata": {},
   "source": [
    "## Define function to compare all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c8d0bd39-fc5a-4d01-bdd5-0e383778e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithms(algorithms, run_times, top_k, data_path, output_path):\n",
    "    algorithm_functions = {\n",
    "        'CauTrigger': run_cautrigger,\n",
    "        'CEFCON': run_cefcon,\n",
    "        'CellOracle': run_celloracle,\n",
    "        'SCENIC': run_scenic,\n",
    "    }\n",
    "    algorithm_functions_to_run = {key: algorithm_functions[key] for key in algorithms if key in algorithm_functions}\n",
    "    all_runs_results = {}\n",
    "    algorithms_to_remove = []\n",
    "\n",
    "    for algorithm_name in algorithm_functions_to_run.keys():\n",
    "        if os.path.exists(os.path.join(output_path, f'hESC_{algorithm_name}.csv')):\n",
    "            all_runs_results[algorithm_name] = pd.read_csv(os.path.join(output_path, f'hESC_{algorithm_name}.csv'), index_col=0)\n",
    "            # with open(os.path.join(output_path, f'RGMs_{algorithm_name}.pkl'), 'rb') as f:\n",
    "            #     all_RGMs = pickle.load(f)\n",
    "            # all_RGMs[algorithm_name] = RGMs\n",
    "            algorithms_to_remove.append(algorithm_name)\n",
    "    for algorithm_name in algorithms_to_remove:\n",
    "        del algorithm_functions_to_run[algorithm_name]\n",
    "    if len(algorithm_functions_to_run) == 0:\n",
    "        return all_runs_results\n",
    "    all_runs_results = {}\n",
    "    \n",
    "    for algorithm_name in algorithm_functions_to_run.keys():\n",
    "        run_algorithm = algorithm_functions[algorithm_name]\n",
    "        columns = [f'{algorithm_name}_{i+1}' for i in range(run_times)]\n",
    "        top_k_genes_df = pd.DataFrame(index=range(top_k), columns=columns)\n",
    "        for i in range(run_times):\n",
    "            gene_info_df = run_algorithm(data_path, output_path, seed=i)\n",
    "            top_k_genes = gene_info_df.index[:top_k]\n",
    "            top_k_genes_df[f'{algorithm_name}_{i+1}'] = top_k_genes\n",
    "        all_runs_results[algorithm_name] = top_k_genes_df\n",
    "    return all_runs_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff35c2-155c-47ed-9bbf-cdfe06b34073",
   "metadata": {},
   "source": [
    "## Load ground truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f50392-0e01-459b-85e4-66139e0a6264",
   "metadata": {},
   "source": [
    "The GO sets are directly from https://www.geneontology.org/, ESC_Cell2011 and ESC_Reproduction2008 are from https://github.com/WPZgithub/CEFCON/tree/main/ground_truths/driver_regulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88a165d5-13b9-4902-a301-52107d186236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(data_path):\n",
    "    hESC_ground_truth = {}\n",
    "    Trrust_human = pd.read_table(os.path.join(data_path, 'trrust_rawdata.human.tsv'), header=None)\n",
    "    Trrust_human_TF = Trrust_human.iloc[:, 0].dropna().unique()\n",
    "    hESC_files = [\n",
    "        ('cell_fate_commitment', 'GO_CELL_FATE_COMMITMENT.txt'),\n",
    "        ('stem_cell_population_maintenance', 'GO_STEM_CELL_POPULATION_MAINTENANCE.txt'),\n",
    "        ('endoderm_development', 'GO_ENDODERM_DEVELOPMENT.txt')\n",
    "    ]\n",
    "    for name, file in hESC_files:\n",
    "        df = pd.read_csv(os.path.join(data_path, file))\n",
    "        hESC_ground_truth[name] = set(np.intersect1d(df.iloc[:, 0], Trrust_human_TF))\n",
    "    cell2011_genes = set(pd.read_csv(os.path.join(data_path, 'ESC_Cell2011.csv'), encoding='latin1')['TFs'])\n",
    "    reproduction2008_genes = set(pd.read_csv(os.path.join(data_path, 'ESC_Reproduction2008.csv'))['TFs'])\n",
    "    literature_curated = cell2011_genes.union(reproduction2008_genes)\n",
    "    hESC_ground_truth['literature_curated'] = literature_curated\n",
    "    hESC_ground_truth['all'] = set.union(*hESC_ground_truth.values())\n",
    "    return hESC_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f27beb-921a-484f-bc43-055658f30c91",
   "metadata": {},
   "source": [
    "## Define function to calculate metrics and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6de3ef1c-1311-4ee4-bc63-849a15802f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_metrics(algorithm_results, ground_truth, top_k=20):\n",
    "    from scipy.stats import hypergeom\n",
    "    precision_matrix = []\n",
    "    recall_matrix = []\n",
    "    p_value_matrix = []\n",
    "    f1_score_matrix = []\n",
    "    if isinstance(ground_truth, pd.DataFrame):\n",
    "        true_genes = set(ground_truth.iloc[:, 0].values)\n",
    "    elif isinstance(ground_truth, np.ndarray):\n",
    "        true_genes = set(np.unique(ground_truth))\n",
    "    else:\n",
    "        true_genes = ground_truth\n",
    "    for method in algorithm_results.columns:\n",
    "        precision_col = []\n",
    "        recall_col = []\n",
    "        p_value_col = []\n",
    "        f1_score_col = []\n",
    "        for K in range(1, top_k + 1):\n",
    "            pred_genes = set(algorithm_results[method].iloc[:K].str.upper())\n",
    "            TP = len(pred_genes.intersection(true_genes))\n",
    "            precision = TP / K\n",
    "            recall = TP / len(true_genes)\n",
    "            f1_score = 2 * precision * recall / (precision + recall) if precision + recall != 0 else 0\n",
    "            p_value = hypergeom.sf(TP - 1, 15000, len(true_genes), K)\n",
    "            precision_col.append(precision)\n",
    "            recall_col.append(recall)\n",
    "            p_value_col.append(p_value)\n",
    "            f1_score_col.append(f1_score)\n",
    "        precision_matrix.append(precision_col)\n",
    "        recall_matrix.append(recall_col)\n",
    "        p_value_matrix.append(p_value_col)\n",
    "        f1_score_matrix.append(f1_score_col)\n",
    "    metrics = {\n",
    "        'precision': pd.DataFrame(precision_matrix, columns=range(1, top_k + 1), index=algorithm_results.columns),\n",
    "        'recall': pd.DataFrame(recall_matrix, columns=range(1, top_k + 1), index=algorithm_results.columns),\n",
    "        'p_value': pd.DataFrame(p_value_matrix, columns=range(1, top_k + 1), index=algorithm_results.columns),\n",
    "        'f1_score': pd.DataFrame(f1_score_matrix, columns=range(1, top_k + 1), index=algorithm_results.columns)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d67acd86-c019-4d34-b851-cd2cc728efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_plot(metric='precision', outpur_dir=False):\n",
    "    df2plot_dict = {}\n",
    "    for i in hESC_ground_truth.keys():\n",
    "        df2plot_dict[i] = pd.DataFrame()\n",
    "        for j in hESC_algorithm_ret.keys():\n",
    "            hESC_metrics = get_top_k_metrics(hESC_algorithm_ret[j], hESC_ground_truth[i])\n",
    "            df2plot_dict[i] = pd.concat([df2plot_dict[i], hESC_metrics[metric]], axis=0)\n",
    "    df1 = df2plot_dict['cell_fate_commitment'].reset_index().melt(id_vars='index', var_name='timepoint', value_name='value')\n",
    "    df1[['new_col1', 'new_col2']] = df1['index'].str.split('_', expand=True)\n",
    "    df1['gt'] = 'cell fate commitment'\n",
    "    \n",
    "    df2 = df2plot_dict['stem_cell_population_maintenance'].reset_index().melt(id_vars='index', var_name='timepoint', value_name='value')\n",
    "    df2[['new_col1', 'new_col2']] = df2['index'].str.split('_', expand=True)\n",
    "    df2['gt'] = 'stem cell population maintenance'\n",
    "    \n",
    "    df3 = df2plot_dict['endoderm_development'].reset_index().melt(id_vars='index', var_name='timepoint', value_name='value')\n",
    "    df3[['new_col1', 'new_col2']] = df3['index'].str.split('_', expand=True)\n",
    "    df3['gt'] = 'endoderm development'\n",
    "    \n",
    "    df4 = df2plot_dict['literature_curated'].reset_index().melt(id_vars='index', var_name='timepoint', value_name='value')\n",
    "    df4[['new_col1', 'new_col2']] = df4['index'].str.split('_', expand=True)\n",
    "    df4['gt'] = 'literature curated'\n",
    "    \n",
    "    df5 = df2plot_dict['all'].reset_index().melt(id_vars='index', var_name='timepoint', value_name='value')\n",
    "    df5[['new_col1', 'new_col2']] = df5['index'].str.split('_', expand=True)\n",
    "    df5['gt'] = 'all'\n",
    "    \n",
    "    merged_df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "    \n",
    "    g = sns.relplot(data=merged_df, x=\"timepoint\", y=\"value\", hue=\"new_col1\", kind=\"line\", ci=90, marker='o', col='gt')\n",
    "    (g.map(plt.axhline, y=0, color=\".7\", dashes=(2, 1), zorder=0)\n",
    "      .set_axis_labels(\"Rank cutoff\", metric.capitalize())\n",
    "      .set_titles(\"{col_name}\")\n",
    "      .set(xticks=range(int(merged_df['timepoint'].min()), int(merged_df['timepoint'].max())+1))\n",
    "      .tight_layout(w_pad=0)\n",
    "      )\n",
    "    g.legend.set_title('')\n",
    "    g.fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=4)\n",
    "    if outpur_dir:\n",
    "        g.savefig(f'{outpur_dir}{metric}.png')\n",
    "        g.savefig(f'{outpur_dir}{metric}.pdf')\n",
    "    return df2plot_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b39eb2-c23c-4d46-bde6-8846919be6c4",
   "metadata": {},
   "source": [
    "## Run and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a8ba61c8-45c6-499a-8153-1fc50e972827",
   "metadata": {},
   "outputs": [],
   "source": [
    "hESC_ground_truth = load_ground_truth(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "73a236b5-a279-488c-add9-5424fbeb5601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hESC_algorithm_ret = run_algorithms(algorithms=['CauTrigger', 'CellOracle', 'CEFCON', 'SCENIC'], data_path=data_path, output_path=output_path, run_times=10, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a736883b-f0a3-496e-a068-55ed5f670f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:18:54,272 - INFO - maxp pruned\n",
      "2025-06-05 13:18:54,284 - INFO - cmap pruned\n",
      "2025-06-05 13:18:54,285 - INFO - kern dropped\n",
      "2025-06-05 13:18:54,285 - INFO - post pruned\n",
      "2025-06-05 13:18:54,285 - INFO - FFTM dropped\n",
      "2025-06-05 13:18:54,288 - INFO - GPOS pruned\n",
      "2025-06-05 13:18:54,293 - INFO - GSUB pruned\n",
      "2025-06-05 13:18:54,293 - INFO - name pruned\n",
      "2025-06-05 13:18:54,303 - INFO - glyf pruned\n",
      "2025-06-05 13:18:54,306 - INFO - Added gid0 to subset\n",
      "2025-06-05 13:18:54,306 - INFO - Added first four glyphs to subset\n",
      "2025-06-05 13:18:54,306 - INFO - Closing glyph list over 'GSUB': 43 glyphs before\n",
      "2025-06-05 13:18:54,307 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'five', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'v', 'zero']\n",
      "2025-06-05 13:18:54,308 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89]\n",
      "2025-06-05 13:18:54,313 - INFO - Closed glyph list over 'GSUB': 48 glyphs after\n",
      "2025-06-05 13:18:54,313 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'fi', 'five', 'fl', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'uniFB00', 'uniFB03', 'uniFB04', 'v', 'zero']\n",
      "2025-06-05 13:18:54,314 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 5038, 5039, 5040, 5041, 5042]\n",
      "2025-06-05 13:18:54,314 - INFO - Closing glyph list over 'MATH': 48 glyphs before\n",
      "2025-06-05 13:18:54,315 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'fi', 'five', 'fl', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'uniFB00', 'uniFB03', 'uniFB04', 'v', 'zero']\n",
      "2025-06-05 13:18:54,315 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 5038, 5039, 5040, 5041, 5042]\n",
      "2025-06-05 13:18:54,316 - INFO - Closed glyph list over 'MATH': 48 glyphs after\n",
      "2025-06-05 13:18:54,316 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'fi', 'five', 'fl', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'uniFB00', 'uniFB03', 'uniFB04', 'v', 'zero']\n",
      "2025-06-05 13:18:54,317 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 5038, 5039, 5040, 5041, 5042]\n",
      "2025-06-05 13:18:54,317 - INFO - Closing glyph list over 'glyf': 48 glyphs before\n",
      "2025-06-05 13:18:54,318 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'fi', 'five', 'fl', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'uniFB00', 'uniFB03', 'uniFB04', 'v', 'zero']\n",
      "2025-06-05 13:18:54,318 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 5038, 5039, 5040, 5041, 5042]\n",
      "2025-06-05 13:18:54,319 - INFO - Closed glyph list over 'glyf': 48 glyphs after\n",
      "2025-06-05 13:18:54,319 - INFO - Glyph names: ['.notdef', '.null', 'C', 'E', 'F', 'I', 'N', 'O', 'P', 'R', 'S', 'T', 'a', 'c', 'd', 'e', 'eight', 'f', 'fi', 'five', 'fl', 'four', 'g', 'i', 'k', 'l', 'm', 'n', 'nine', 'nonmarkingreturn', 'o', 'one', 'p', 'period', 'r', 's', 'seven', 'six', 'space', 't', 'three', 'two', 'u', 'uniFB00', 'uniFB03', 'uniFB04', 'v', 'zero']\n",
      "2025-06-05 13:18:54,319 - INFO - Glyph IDs:   [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 38, 40, 41, 44, 49, 50, 51, 53, 54, 55, 68, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 5038, 5039, 5040, 5041, 5042]\n",
      "2025-06-05 13:18:54,320 - INFO - Retaining 48 glyphs\n",
      "2025-06-05 13:18:54,321 - INFO - head subsetting not needed\n",
      "2025-06-05 13:18:54,321 - INFO - hhea subsetting not needed\n",
      "2025-06-05 13:18:54,321 - INFO - maxp subsetting not needed\n",
      "2025-06-05 13:18:54,322 - INFO - OS/2 subsetting not needed\n",
      "2025-06-05 13:18:54,326 - INFO - hmtx subsetted\n",
      "2025-06-05 13:18:54,331 - INFO - cmap subsetted\n",
      "2025-06-05 13:18:54,332 - INFO - fpgm subsetting not needed\n",
      "2025-06-05 13:18:54,332 - INFO - prep subsetting not needed\n",
      "2025-06-05 13:18:54,332 - INFO - cvt  subsetting not needed\n",
      "2025-06-05 13:18:54,333 - INFO - loca subsetting not needed\n",
      "2025-06-05 13:18:54,333 - INFO - post subsetted\n",
      "2025-06-05 13:18:54,334 - INFO - gasp subsetting not needed\n",
      "2025-06-05 13:18:54,336 - INFO - GDEF subsetted\n",
      "2025-06-05 13:18:54,364 - INFO - GPOS subsetted\n",
      "2025-06-05 13:18:54,367 - INFO - GSUB subsetted\n",
      "2025-06-05 13:18:54,367 - INFO - MATH subsetted\n",
      "2025-06-05 13:18:54,368 - INFO - name subsetting not needed\n",
      "2025-06-05 13:18:54,370 - INFO - glyf subsetted\n",
      "2025-06-05 13:18:54,372 - INFO - head pruned\n",
      "2025-06-05 13:18:54,372 - INFO - OS/2 Unicode ranges pruned: [0]\n",
      "2025-06-05 13:18:54,373 - INFO - glyf pruned\n",
      "2025-06-05 13:18:54,374 - INFO - GDEF pruned\n",
      "2025-06-05 13:18:54,374 - INFO - GPOS pruned\n",
      "2025-06-05 13:18:54,375 - INFO - GSUB pruned\n"
     ]
    }
   ],
   "source": [
    "df2plot_dict = df_to_plot(metric='precision', outpur_dir=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_CT",
   "language": "python",
   "name": "project_ct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
