{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff18c72-6446-40c7-859c-5ca395163f4a",
   "metadata": {},
   "source": [
    "# Benchmark in Norman dataset (PCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f1301-9183-451d-b816-6405b2b8c6cf",
   "metadata": {},
   "source": [
    "The data is from Exploring genetic interaction manifolds constructed from rich single-cell phenotypes, https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133344"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c8982-22fd-4ab4-9e2c-5f7c69a0be89",
   "metadata": {},
   "source": [
    "## Import libraries and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36b748c-8c89-4e61-aa65-0df87595620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "BASE_DIR = '/your/working/directory'\n",
    "case_path = os.path.join(BASE_DIR, 'BenchmarkNorman')\n",
    "data_path = os.path.join(case_path, 'data')\n",
    "output_path = os.path.join(case_path, 'output/')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "data_name = 'perturb_processed.h5ad'\n",
    "prior_network_name = 'trrust_rawdata.human.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51869d-dbb8-4e7a-b2ea-d74067bddfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gene_names(variable):\n",
    "    import re\n",
    "    gene_name = re.sub(r'ctrl|\\+', '', variable)\n",
    "    return gene_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fdaa8-65a8-402f-a7fd-71b68cb62775",
   "metadata": {},
   "source": [
    "## Our method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff80fd-0832-4ff0-9e70-03531df4af7a",
   "metadata": {},
   "source": [
    "We provide our result in pickle form file to save your time, if you want to run by your own, please comment out the first block codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e948e3-d9fa-4d10-af8a-1dbf450ddd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ct(data_path, train_test_dict, norman_adata, TFs, nonTFs):\n",
    "    \n",
    "    if os.path.exists(os.path.join(data_path, 'CauTrigger_results_pcc_all.pickle')):\n",
    "        with open(os.path.join(data_path, \"CauTrigger_results_pcc_all.pickle\"), \"rb\") as file:\n",
    "            CauTrigger_pearsonr_dict = pickle.load(file)\n",
    "        return CauTrigger_pearsonr_dict\n",
    "\n",
    "\n",
    "    from CauTrigger.model import CauTrigger\n",
    "    from CauTrigger.utils import set_seed\n",
    "    down = nonTFs\n",
    "    down = np.concatenate([TFs, nonTFs])\n",
    "    CauTrigger_pearsonr_dict = {'single':[], 'combo_seen0':[], 'combo_seen1':[], 'combo_seen2':[]}\n",
    "\n",
    "    norman_adata_TF = norman_adata[:, np.isin(norman_adata.var['gene_name'], TFs)]\n",
    "    norman_adata_nonTF = norman_adata[:, np.isin(norman_adata.var['gene_name'], nonTFs)]\n",
    "    norman_adata_TF_ctrl = norman_adata_TF[norman_adata_TF.obs['condition'] == 'ctrl', :]\n",
    "    norman_adata_nonTF_ctrl = norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == 'ctrl', :]\n",
    "    norman_adata_for_CT_ctrl = norman_adata_TF_ctrl.copy()\n",
    "    norman_adata_for_CT_ctrl.obs['labels'] = np.repeat(0, norman_adata_for_CT_ctrl.shape[0])\n",
    "    norman_adata_for_CT_ctrl.obsm['X_down'] = norman_adata_nonTF_ctrl.X.copy()\n",
    "    pert = np.concatenate([\n",
    "    train_test_dict['single_train'],\n",
    "    train_test_dict['combo_seen0_train'],\n",
    "    train_test_dict['combo_seen1_train'],\n",
    "    train_test_dict['combo_seen2_train']])\n",
    "    norman_adata_TF_pert = norman_adata_TF[norman_adata_TF.obs['condition'].isin(pert), :]\n",
    "    norman_adata_nonTF_pert = norman_adata_nonTF[norman_adata_nonTF.obs['condition'].isin(pert), :]\n",
    "    norman_adata_for_CT_pert = norman_adata_TF_pert.copy()\n",
    "    norman_adata_for_CT_pert.obs['labels'] = np.repeat(1, norman_adata_for_CT_pert.shape[0])\n",
    "    norman_adata_for_CT_pert.obsm['X_down'] = norman_adata_nonTF_pert.X.copy()\n",
    "    adata_for_train = anndata.concat([norman_adata_for_CT_ctrl, norman_adata_for_CT_pert])\n",
    "    adata_for_train.X = adata_for_train.X.todense()\n",
    "    adata_for_train.obsm['X_down'] = adata_for_train.obsm['X_down'].todense()\n",
    "    set_seed(42)\n",
    "    model = CauTrigger(\n",
    "        adata_for_train,\n",
    "        n_causal=2,\n",
    "        n_latent=10,\n",
    "        n_hidden=128,\n",
    "        n_layers_encoder=0,\n",
    "        n_layers_decoder=0,\n",
    "        n_layers_dpd=0,\n",
    "        dropout_rate_encoder=0.1,\n",
    "        dropout_rate_decoder=0.1,\n",
    "        dropout_rate_dpd=0.1,\n",
    "        use_batch_norm='both',\n",
    "        use_batch_norm_dpd=True,\n",
    "        decoder_linear=True,\n",
    "        dpd_linear=False,\n",
    "        init_weight=None,\n",
    "        init_thresh=0.0,\n",
    "        update_down_weight=False,\n",
    "        attention=False,\n",
    "        att_mean=False,\n",
    "    )\n",
    "    weight_scheme = {'stage1': [0.1, 2.0, 2.0, 0.01, 0.5, 1.0, 0.0, 0.0, 0.0],\n",
    "                     'stage2': [0.4, 2.0, 2.0, 0.1, 0.5, 0.5, 0.0, 0.01, 0.01],\n",
    "                     'stage3': [0.8, 2.0, 2.0, 0.1, 0.1, 0.1, 1.0, 0.1, 0.1],\n",
    "                     'stage4': [1, 2.0, 2.0, 0.01, 0.01, 0.01, 1.0, 1.0, 1.0]}\n",
    "    if adata_for_train.shape[0] > 2000:\n",
    "        max_epochs = 200\n",
    "    else:\n",
    "        max_epochs = 500\n",
    "    model.train(max_epochs=max_epochs, im_factor=1, weight_scheme=weight_scheme)\n",
    "    for single_test in train_test_dict['single_test']:\n",
    "        pert = single_test + '+ctrl'\n",
    "        norman_adata_for_CT_ctrl_test1 = norman_adata_for_CT_ctrl.copy()\n",
    "        norman_adata_for_CT_ctrl_test1.X[:, norman_adata_for_CT_ctrl_test1.var['gene_name'] == single_test] = 2 * norman_adata_for_CT_ctrl.X.max()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model_output = model.module.forward(torch.Tensor(norman_adata_for_CT_ctrl_test1.X.todense()).to('cuda:0'))\n",
    "        pred_up = model_output['x_up_rec1'].cpu().numpy()\n",
    "        pred_down = model_output['x_down_rec_alpha'].cpu().numpy()\n",
    "        pred_all = np.concatenate([pred_up, pred_down], axis=1)\n",
    "        pred_all = pd.DataFrame(pred_all, columns=np.concatenate(\n",
    "            [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "        truth_up = norman_adata_TF[norman_adata_TF.obs['condition'] == pert, :].X.copy().todense()\n",
    "        truth_down = norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == pert, :].X.copy().todense()\n",
    "        truth_all = np.concatenate([truth_up, truth_down], axis=1)\n",
    "        truth_all = pd.DataFrame(truth_all, columns=np.concatenate(\n",
    "            [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "        ctrl = np.concatenate([norman_adata_for_CT_ctrl.X.copy().todense(),\n",
    "                               norman_adata_for_CT_ctrl.obsm['X_down'].copy().todense()], axis=1)\n",
    "        ctrl = pd.DataFrame(ctrl, columns=np.concatenate(\n",
    "            [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "        if pred_all.filter(down).shape[1] > 1:\n",
    "            pred_deg = pred_all.filter(down).mean(0)\n",
    "            truth_deg = truth_all.filter(down).mean(0)\n",
    "            ctrl_deg = ctrl.filter(down).mean(0)\n",
    "            res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                    truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "        else:\n",
    "            res_pearsonr = np.nan\n",
    "        CauTrigger_pearsonr_dict['single'].append(res_pearsonr)\n",
    "    for key in ['combo_seen0', 'combo_seen1', 'combo_seen2']:\n",
    "        for combo in train_test_dict[key]:\n",
    "            pert = combo\n",
    "            norman_adata_for_CT_ctrl_test1 = norman_adata_for_CT_ctrl.copy()\n",
    "            norman_adata_for_CT_ctrl_test1.X[:, norman_adata_for_CT_ctrl_test1.var['gene_name'] == pert.split('+')[0]] = 2 * norman_adata_for_CT_ctrl.X.max()\n",
    "            norman_adata_for_CT_ctrl_test1.X[:, norman_adata_for_CT_ctrl_test1.var['gene_name'] == pert.split('+')[1]] = 2 * norman_adata_for_CT_ctrl.X.max()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                model_output = model.module.forward(\n",
    "                    torch.Tensor(norman_adata_for_CT_ctrl_test1.X.todense()).to('cuda:0'))\n",
    "            pred_up = model_output['x_up_rec1'].cpu().numpy()\n",
    "            pred_down = model_output['x_down_rec_alpha'].cpu().numpy()\n",
    "            pred_all = np.concatenate([pred_up, pred_down], axis=1)\n",
    "            pred_all = pd.DataFrame(pred_all, columns=np.concatenate(\n",
    "                [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "            truth_up = norman_adata_TF[norman_adata_TF.obs['condition'] == pert, :].X.copy().todense()\n",
    "            truth_down = norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == pert, :].X.copy().todense()\n",
    "            truth_all = np.concatenate([truth_up, truth_down], axis=1)\n",
    "            truth_all = pd.DataFrame(truth_all, columns=np.concatenate(\n",
    "                [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "            ctrl = np.concatenate([norman_adata_for_CT_ctrl.X.copy().todense(),\n",
    "                                   norman_adata_for_CT_ctrl.obsm['X_down'].copy().todense()], axis=1)\n",
    "            ctrl = pd.DataFrame(ctrl, columns=np.concatenate(\n",
    "                [norman_adata_TF_pert.var.gene_name, norman_adata_nonTF_pert.var.gene_name]))\n",
    "            if pred_all.filter(down).shape[1] > 1:\n",
    "                pred_deg = pred_all.filter(down).mean(0)\n",
    "                truth_deg = truth_all.filter(down).mean(0)\n",
    "                ctrl_deg = ctrl.filter(down).mean(0)\n",
    "                res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                        truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "            else:\n",
    "                res_pearsonr = np.nan\n",
    "            CauTrigger_pearsonr_dict[key].append(res_pearsonr)\n",
    "    with open(os.path.join(data_path, \"CauTrigger_results_pcc_all.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(CauTrigger_pearsonr_dict, file)\n",
    "    return CauTrigger_pearsonr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbac8d-b23f-4cea-b425-e9ad49880c31",
   "metadata": {},
   "source": [
    "## GEARS method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0af28-1f95-4291-957e-3df8dec59765",
   "metadata": {},
   "source": [
    "We provide our result in pickle form file to save your time, if you want to run by your own, please comment out the first block codes below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28181e-653a-4484-b27b-a88f5c1caace",
   "metadata": {},
   "source": [
    "Please prepare or install GEARS and we also provide our trained gears model to save your time, if you want to train by your own, please uncomment the lines below and comment out 'gears_model.load_pretrained' line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734db92-d19c-4663-9dcd-3e088dbe5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gears(data_path, norman_adata, TFs, nonTFs):\n",
    "    \n",
    "    if os.path.exists(os.path.join(data_path, 'GEARS_results_pcc_all.pickle')):\n",
    "        with open(os.path.join(data_path, \"GEARS_results_pcc_all.pickle\"), \"rb\") as file:\n",
    "            GEARS_pearsonr_dict = pickle.load(file)\n",
    "        return GEARS_pearsonr_dict\n",
    "\n",
    "    from gears import PertData, GEARS\n",
    "    GEARS_pearsonr_dict = {'single':[], 'combo_seen0':[], 'combo_seen1':[], 'combo_seen2':[]}\n",
    "    down = nonTFs\n",
    "    down = np.concatenate([TFs, nonTFs])\n",
    "    pert_data = PertData(data_path=data_path, gene_set_path=os.path.join(data_path, 'essential_all_data_pert_genes.pkl'))\n",
    "    pert_data.load(data_path=data_path)\n",
    "    pert_data.prepare_split(split='simulation', seed=1)\n",
    "    pert_data.get_dataloader(batch_size=32, test_batch_size=128)\n",
    "    gears_model = GEARS(pert_data, device='cuda:0', weight_bias_track=False)\n",
    "\n",
    "    # gears_model.model_initialize(hidden_size=64)\n",
    "    # gears_model.train(epochs=10, lr=1e-4)\n",
    "    # os.makedirs(os.path.join(data_path, 'gears_model_pcc'), exist_ok=True)\n",
    "    # gears_model.save_model(os.path.join(data_path, 'gears_model_pcc'))\n",
    "\n",
    "    gears_model.load_pretrained(os.path.join(data_path, 'gears_model_pcc'))\n",
    "\n",
    "    with open(os.path.join(data_path, 'splits', \"data_simulation_1_0.75_subgroup.pkl\"), \"rb\") as file:\n",
    "        subgroups = pickle.load(file)\n",
    "    test_subgroup = subgroups['test_subgroup']\n",
    "    for unseen_single in test_subgroup['unseen_single']:\n",
    "        gene = extract_gene_names(unseen_single)\n",
    "        pert = gene+'+ctrl'\n",
    "        pred = pd.DataFrame(gears_model.predict([[gene]])[gene]).T\n",
    "        pred.columns = norman_adata.var.gene_name\n",
    "        truth = pd.DataFrame(norman_adata[norman_adata.obs['condition'] == pert, :].X.toarray().mean(0)).T\n",
    "        truth.columns = norman_adata.var.gene_name\n",
    "        ctrl = pd.DataFrame(norman_adata[norman_adata.obs['condition'] == 'ctrl', :].X.toarray().mean(0)).T\n",
    "        ctrl.columns = norman_adata.var.gene_name\n",
    "        if pred.filter(down).shape[1] > 1:\n",
    "            pred_deg = pred.filter(down)\n",
    "            truth_deg = truth.filter(down)\n",
    "            ctrl_deg = ctrl.filter(down)\n",
    "            res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                    truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "        else:\n",
    "            res_pearsonr = np.nan\n",
    "        GEARS_pearsonr_dict['single'].append(res_pearsonr)\n",
    "    for key in ['combo_seen0', 'combo_seen1', 'combo_seen2']:\n",
    "        for combo in test_subgroup[key]:\n",
    "            pert = combo\n",
    "            pred = pd.DataFrame(gears_model.predict([combo.split('+')])['_'.join(combo.split('+'))]).T\n",
    "            pred.columns = norman_adata.var.gene_name\n",
    "            truth = pd.DataFrame(norman_adata[norman_adata.obs['condition'] == pert, :].X.toarray().mean(0)).T\n",
    "            truth.columns = norman_adata.var.gene_name\n",
    "            ctrl = pd.DataFrame(norman_adata[norman_adata.obs['condition'] == 'ctrl', :].X.toarray().mean(0)).T\n",
    "            ctrl.columns = norman_adata.var.gene_name\n",
    "            if pred.filter(down).shape[1] > 1:\n",
    "                pred_deg = pred.filter(down)\n",
    "                truth_deg = truth.filter(down)\n",
    "                ctrl_deg = ctrl.filter(down)\n",
    "                res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                        truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "            else:\n",
    "                res_mse = np.nan\n",
    "                res_pearsonr = np.nan\n",
    "            GEARS_pearsonr_dict[key].append(res_pearsonr)\n",
    "    with open(os.path.join(data_path, \"GEARS_results_pcc_all.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(GEARS_pearsonr_dict, file)\n",
    "    return GEARS_pearsonr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a677c0-22cd-4e89-a090-0e52dd153edf",
   "metadata": {},
   "source": [
    "## CPA method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf7a36-70a1-4b97-8275-c729741a1fff",
   "metadata": {},
   "source": [
    "We provide our result in pickle form file to save your time, if you want to run by your own, please comment out the first block codes below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90f29d-2390-46c8-aa5c-2979bd60d245",
   "metadata": {},
   "source": [
    "Please prepare or install CPA, this part uses the intermediate file 'data_simulation_1_0.75_subgroup.pkl' from previous GEARS part, please insure this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e99a19-ce9c-4d93-ac09-2c946cbd1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpa(data_path, norman_adata, TFs, nonTFs):\n",
    "    \n",
    "    if os.path.exists(os.path.join(data_path, 'CPA_results_pcc_all.pickle')):\n",
    "        with open(os.path.join(data_path, \"CPA_results_pcc_all.pickle\"), \"rb\") as file:\n",
    "            cpa_pearsonr_dict = pickle.load(file)\n",
    "        return cpa_pearsonr_dict\n",
    "\n",
    "    down = nonTFs\n",
    "    down = np.concatenate([TFs, nonTFs])\n",
    "    cpa_pearsonr_dict = {'single':[], 'combo_seen0':[], 'combo_seen1':[], 'combo_seen2':[]}\n",
    "    with open(os.path.join(data_path, 'splits', \"data_simulation_1_0.75_subgroup.pkl\"), \"rb\") as file:\n",
    "        subgroups = pickle.load(file)\n",
    "    test_subgroup = subgroups['test_subgroup']\n",
    "    val_subgroup = subgroups['val_subgroup']\n",
    "\n",
    "    def run_cpa_model(data_path, norman_adata, test_subgroup=test_subgroup, val_subgroup=val_subgroup):\n",
    "        import cpa\n",
    "        norman_adata_cpa = norman_adata.copy()\n",
    "        norman_adata_cpa.obs['condition'] = pd.Categorical(norman_adata_cpa.obs['condition'])\n",
    "        norman_adata_cpa.obs['split'] = 'train'\n",
    "        norman_adata_cpa.obs.loc[\n",
    "            norman_adata_cpa.obs['condition'].isin(np.concatenate(list(test_subgroup.values()))), 'split'] = 'valid'\n",
    "        norman_adata_cpa.obs.loc[\n",
    "            norman_adata_cpa.obs['condition'].isin(np.concatenate(list(val_subgroup.values()))), 'split'] = 'ood'\n",
    "        cpa.CPA.setup_anndata(norman_adata_cpa,\n",
    "                              perturbation_key='condition',\n",
    "                              control_group='ctrl',\n",
    "                              dosage_key='dose_val',\n",
    "                              categorical_covariate_keys=['cell_type'],\n",
    "                              is_count_data=False,\n",
    "                              deg_uns_key='rank_genes_groups_cov',\n",
    "                              deg_uns_cat_key='condition_name',\n",
    "                              max_comb_len=2,\n",
    "                              )\n",
    "        model_params = {\n",
    "            \"n_latent\": 32,\n",
    "            \"recon_loss\": \"nb\",\n",
    "            \"doser_type\": \"linear\",\n",
    "            \"n_hidden_encoder\": 256,\n",
    "            \"n_layers_encoder\": 4,\n",
    "            \"n_hidden_decoder\": 256,\n",
    "            \"n_layers_decoder\": 2,\n",
    "            \"use_batch_norm_encoder\": True,\n",
    "            \"use_layer_norm_encoder\": False,\n",
    "            \"use_batch_norm_decoder\": False,\n",
    "            \"use_layer_norm_decoder\": False,\n",
    "            \"dropout_rate_encoder\": 0.2,\n",
    "            \"dropout_rate_decoder\": 0.0,\n",
    "            \"variational\": False,\n",
    "            \"seed\": 8206,\n",
    "        }\n",
    "        trainer_params = {\n",
    "            \"n_epochs_kl_warmup\": None,\n",
    "            \"n_epochs_adv_warmup\": 50,\n",
    "            \"n_epochs_mixup_warmup\": 10,\n",
    "            \"n_epochs_pretrain_ae\": 10,\n",
    "            \"mixup_alpha\": 0.1,\n",
    "            \"lr\": 0.0001,\n",
    "            \"wd\": 3.2170178270865573e-06,\n",
    "            \"adv_steps\": 3,\n",
    "            \"reg_adv\": 10.0,\n",
    "            \"pen_adv\": 20.0,\n",
    "            \"adv_lr\": 0.0001,\n",
    "            \"adv_wd\": 7.051355554517135e-06,\n",
    "            \"n_layers_adv\": 2,\n",
    "            \"n_hidden_adv\": 128,\n",
    "            \"use_batch_norm_adv\": True,\n",
    "            \"use_layer_norm_adv\": False,\n",
    "            \"dropout_rate_adv\": 0.3,\n",
    "            \"step_size_lr\": 25,\n",
    "            \"do_clip_grad\": False,\n",
    "            \"adv_loss\": \"cce\",\n",
    "            \"gradient_clip_value\": 5.0,\n",
    "        }\n",
    "        cpa_model = cpa.CPA(adata=norman_adata_cpa,\n",
    "                            split_key='split',\n",
    "                            train_split='train',\n",
    "                            valid_split='valid',\n",
    "                            test_split='ood',\n",
    "                            **model_params,\n",
    "                            )\n",
    "        os.makedirs(os.path.join(data_path, 'CPA_model'), exist_ok=True)\n",
    "        cpa_model.train(max_epochs=2000,\n",
    "                        use_gpu=True,\n",
    "                        batch_size=2048,\n",
    "                        plan_kwargs=trainer_params,\n",
    "                        early_stopping_patience=5,\n",
    "                        check_val_every_n_epoch=5,\n",
    "                        save_path=os.path.join(data_path, 'CPA_model', 'PCC'),\n",
    "                        )\n",
    "        norman_adata_cpa.layers['truth'] = norman_adata_cpa.X.copy()\n",
    "        ctrl_adata = norman_adata_cpa[norman_adata_cpa.obs['condition'] == 'ctrl'].copy()\n",
    "        norman_adata_cpa.X = ctrl_adata.X[np.random.choice(ctrl_adata.n_obs, size=norman_adata_cpa.n_obs, replace=True), :]\n",
    "        cpa_model.predict(norman_adata_cpa, batch_size=2048)\n",
    "        norman_adata_cpa.layers['CPA_pred'] = norman_adata_cpa.obsm['CPA_pred'].copy()\n",
    "        subset_indices = norman_adata_cpa.obs['condition'].isin(np.concatenate(list(test_subgroup.values())))\n",
    "        norman_adata_cpa_filter = norman_adata_cpa[subset_indices].copy()\n",
    "        for layer in norman_adata_cpa.layers.keys():\n",
    "            norman_adata_cpa_filter.layers[layer] = norman_adata_cpa.layers[layer][subset_indices, :]\n",
    "        norman_adata_cpa_filter.uns.clear()\n",
    "        norman_adata_cpa_filter.obsm.clear()\n",
    "        norman_adata_cpa_filter.write_h5ad(os.path.join(data_path, 'CPA_result_adata.h5ad'))\n",
    "        return norman_adata_cpa_filter\n",
    "\n",
    "    norman_adata_cpa_filter = run_cpa_model(data_path, norman_adata)\n",
    "\n",
    "    for unseen_single in test_subgroup['unseen_single']:\n",
    "        gene = extract_gene_names(unseen_single)\n",
    "        pert = gene + '+ctrl'\n",
    "        pred_indices = norman_adata_cpa_filter.obs['condition'] == pert\n",
    "        pred = pd.DataFrame(norman_adata_cpa_filter.layers['CPA_pred'][pred_indices, :].mean(0)).T\n",
    "        pred.columns = norman_adata_cpa_filter.var.gene_name\n",
    "        truth = pd.DataFrame(norman_adata_cpa_filter.layers['truth'][pred_indices, :].mean(0))\n",
    "        truth.columns = norman_adata_cpa_filter.var.gene_name\n",
    "        ctrl = pd.DataFrame(norman_adata_cpa_filter.X.mean(0))\n",
    "        ctrl.columns = norman_adata_cpa_filter.var.gene_name\n",
    "        if pred.filter(down).shape[1] > 1:\n",
    "            pred_deg = pred.filter(down)\n",
    "            truth_deg = truth.filter(down)\n",
    "            ctrl_deg = ctrl.filter(down)\n",
    "            res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                    truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "        else:\n",
    "            res_pearsonr = np.nan\n",
    "        cpa_pearsonr_dict['single'].append(res_pearsonr)\n",
    "    for key in ['combo_seen0', 'combo_seen1', 'combo_seen2']:\n",
    "        for combo in test_subgroup[key]:\n",
    "            pert = combo\n",
    "            pred_indices = norman_adata_cpa_filter.obs['condition'] == pert\n",
    "            pred = pd.DataFrame(norman_adata_cpa_filter.layers['CPA_pred'][pred_indices, :].mean(0)).T\n",
    "            pred.columns = norman_adata_cpa_filter.var.gene_name\n",
    "            truth = pd.DataFrame(norman_adata_cpa_filter.layers['truth'][pred_indices, :].mean(0))\n",
    "            truth.columns = norman_adata_cpa_filter.var.gene_name\n",
    "            ctrl = pd.DataFrame(norman_adata_cpa_filter.X.mean(0))\n",
    "            ctrl.columns = norman_adata_cpa_filter.var.gene_name\n",
    "            if pred.filter(down).shape[1] > 1:\n",
    "                pred_deg = pred.filter(down)\n",
    "                truth_deg = truth.filter(down)\n",
    "                ctrl_deg = ctrl.filter(down)\n",
    "                res_pearsonr = pearsonr(pred_deg.values.flatten() - ctrl_deg.values.flatten(),\n",
    "                                        truth_deg.values.flatten() - ctrl_deg.values.flatten())[0]\n",
    "            else:\n",
    "                res_pearsonr = np.nan\n",
    "            cpa_pearsonr_dict[key].append(res_pearsonr)\n",
    "\n",
    "    with open(os.path.join(data_path, \"CPA_results_pcc_all.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(cpa_pearsonr_dict, file)\n",
    "    return cpa_pearsonr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d2278-3b48-474f-9e3f-13c19b7a233a",
   "metadata": {},
   "source": [
    "## Define function to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a9be0f-1985-4c1a-b4d9-2a6298cf8a97",
   "metadata": {},
   "source": [
    "'RHOXF2BB+ctrl', 'LYL1+IER5L', 'ctrl+IER5L', 'KIAA1804+ctrl', 'IER5L+ctrl', 'RHOXF2BB+ZBTB25', 'RHOXF2BB+SET' are filtered because 'These perturbations are not in the GO graph and their perturbation can thus not be predicted' returned by GEARS, and you also can see this return in https://github.com/snap-stanford/GEARS/blob/master/demo/data_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621bd7a-10fd-4157-9cf9-2f79e33a0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(data_path, output_path, data_name, prior_network_name):\n",
    "    norman_adata = sc.read_h5ad(os.path.join(data_path, data_name))\n",
    "    norman_adata = norman_adata[~norman_adata.obs['condition'].isin(\n",
    "        ['RHOXF2BB+ctrl', 'LYL1+IER5L', 'ctrl+IER5L', 'KIAA1804+ctrl', 'IER5L+ctrl', 'RHOXF2BB+ZBTB25',\n",
    "         'RHOXF2BB+SET']), :]\n",
    "    conditions = np.unique(norman_adata.obs['condition'])\n",
    "    pairs = conditions\n",
    "    valid_pairs = {\n",
    "        (min(pair, reversed_pair), max(pair, reversed_pair))\n",
    "        for pair in pairs if '+' in pair\n",
    "        for reversed_pair in ['+'.join(reversed(pair.split('+')))]\n",
    "        if reversed_pair in pairs\n",
    "    }\n",
    "    unique_valid_pairs = list(valid_pairs)\n",
    "    df = norman_adata.obs.copy()\n",
    "    condition_map = {pair[0]: pair[0] for pair in unique_valid_pairs}\n",
    "    condition_map.update({pair[1]: pair[0] for pair in unique_valid_pairs})\n",
    "    df['condition'] = df['condition'].replace(condition_map)\n",
    "    df['condition_name'] = df['condition'].apply(lambda x: f'K562_{x}_1+1' if x != 'ctrl' else x)\n",
    "    norman_adata.obs = df.copy()\n",
    "    norman_adata.obs['condition'] = norman_adata.obs['condition'].astype(str)\n",
    "    norman_adata.obs['condition'] = pd.Categorical(norman_adata.obs['condition'],\n",
    "                                                   categories=norman_adata.obs['condition'].unique())\n",
    "    conditions = np.unique(norman_adata.obs['condition'])\n",
    "    conditions = np.delete(conditions, np.where(conditions == 'ctrl'))\n",
    "    conditions_gene = []\n",
    "    _ = [conditions_gene.extend(s.split('+')) for s in conditions]\n",
    "    conditions_gene = list(set(conditions_gene))\n",
    "    conditions_gene.remove('ctrl')\n",
    "    Trrust = pd.read_table(os.path.join(data_path, prior_network_name), header=None)\n",
    "    Trrust_TF = Trrust.iloc[:, 0].dropna().unique()\n",
    "    Trrust_nonTF = np.setdiff1d(Trrust.iloc[:, 1].dropna().unique(), Trrust_TF)\n",
    "    TFs = np.intersect1d(Trrust_TF, norman_adata.var['gene_name'])\n",
    "    nonTFs = np.intersect1d(Trrust_nonTF, norman_adata.var['gene_name'])\n",
    "    TFs_to_pert = np.intersect1d(TFs, conditions_gene)\n",
    "    pairs_to_pert = [condition for condition in conditions if\n",
    "                     condition.split('+')[0] in TFs_to_pert and condition.split('+')[1] in TFs_to_pert]\n",
    "    np.random.seed(seed=1)\n",
    "    single_train = np.random.choice(TFs_to_pert, int(len(TFs_to_pert) * 0.75), replace=False)\n",
    "    single_test = np.setdiff1d(TFs_to_pert, single_train)\n",
    "    pairs_to_pert_seen0 = [condition for condition in pairs_to_pert if\n",
    "                     condition.split('+')[0] in single_test and condition.split('+')[1] in single_test]\n",
    "    pairs_to_pert_seen1 = [\n",
    "        condition for condition in pairs_to_pert\n",
    "        if (condition.split('+')[0] in single_train and condition.split('+')[1] in single_test) or\n",
    "           (condition.split('+')[0] in single_test and condition.split('+')[1] in single_train)\n",
    "    ]\n",
    "    pairs_to_pert_seen2 = [condition for condition in pairs_to_pert if\n",
    "                        condition.split('+')[0] in single_train and condition.split('+')[1] in single_train]\n",
    "    pairs_to_pert_seen0_train = np.random.choice(pairs_to_pert_seen0, 1, replace=False)\n",
    "    pairs_to_pert_seen0_test = np.setdiff1d(pairs_to_pert_seen0, pairs_to_pert_seen0_train)\n",
    "    pairs_to_pert_seen1_train = np.random.choice(pairs_to_pert_seen1, 10, replace=False)\n",
    "    pairs_to_pert_seen1_test = np.setdiff1d(pairs_to_pert_seen1, pairs_to_pert_seen1_train)\n",
    "    pairs_to_pert_seen2_train = np.random.choice(pairs_to_pert_seen2, 6, replace=False)\n",
    "    pairs_to_pert_seen2_test = np.setdiff1d(pairs_to_pert_seen2, pairs_to_pert_seen2_train)\n",
    "    train_test_dict = {'single_train': single_train, 'single_test': single_test,\n",
    "                       'combo_seen0_train': pairs_to_pert_seen0_train, 'combo_seen0': pairs_to_pert_seen0_test,\n",
    "                       'combo_seen1_train': pairs_to_pert_seen1_train, 'combo_seen1': pairs_to_pert_seen1_test,\n",
    "                       'combo_seen2_train': pairs_to_pert_seen2_train, 'combo_seen2': pairs_to_pert_seen2_test}\n",
    "    CauTrigger_pearsonr_dict = run_ct(data_path, train_test_dict, norman_adata, TFs, nonTFs)\n",
    "    GEARS_pearsonr_dict= run_gears(data_path, norman_adata, TFs, nonTFs)\n",
    "    cpa_pearsonr_dict = run_cpa(data_path, norman_adata, TFs, nonTFs)\n",
    "    cpa_pearsonr_dict['all'] = np.concatenate(list(cpa_pearsonr_dict.values()))\n",
    "    CauTrigger_pearsonr_dict['all'] = np.concatenate(list(CauTrigger_pearsonr_dict.values()))\n",
    "    GEARS_pearsonr_dict['all'] = np.concatenate(list(GEARS_pearsonr_dict.values()))\n",
    "    data = []\n",
    "    methods = ['CauTrigger', 'GEARS', 'CPA']\n",
    "    for method in methods:\n",
    "        for key in cpa_pearsonr_dict.keys():\n",
    "            if method == 'CPA':\n",
    "                values = cpa_pearsonr_dict[key]\n",
    "            elif method == 'CauTrigger':\n",
    "                values = CauTrigger_pearsonr_dict[key]\n",
    "            elif method == 'GEARS':\n",
    "                values = GEARS_pearsonr_dict[key]\n",
    "            data.extend([[key, method, value] for value in values])\n",
    "    df = pd.DataFrame(data, columns=['Dataset', 'Method', 'Value'])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df, x='Dataset', y='Value', hue='Method', ci='sd', capsize=0.1, palette=sns.color_palette()[3:6])\n",
    "    plt.ylabel('Mean PCC')\n",
    "    plt.xlabel('')\n",
    "    plt.legend(title='Method')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.savefig(os.path.join(output_path, 'Barplot_Mean_PCC.pdf'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_path, 'Barplot_Mean_PCC.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99854fab-1059-4bfc-8bb3-766f212a503c",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc583c6-59dc-4174-854e-140752b3c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark(data_path, output_path, data_name, prior_network_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpa",
   "language": "python",
   "name": "cpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
