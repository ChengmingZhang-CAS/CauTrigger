{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748ef800-1ad4-4dad-8a28-4b470b8238fa",
   "metadata": {},
   "source": [
    "# Benchmark in Norman dataset (ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49128a66-9492-403f-b203-b13c23a9a43f",
   "metadata": {},
   "source": [
    "The data is from 'Exploring genetic interaction manifolds constructed from rich single-cell phenotypes', https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133344"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf0703-8bcd-415b-9be7-6baf75677710",
   "metadata": {},
   "source": [
    "## Import libraries and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db785666-97f9-417a-a6aa-b0d69e391902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "BASE_DIR = '/your/working/directory'\n",
    "case_path = os.path.join(BASE_DIR, 'BenchmarkNorman/')\n",
    "data_path = os.path.join(case_path, 'data/')\n",
    "output_path = os.path.join(case_path, 'output/')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "data_name = 'perturb_processed.h5ad'\n",
    "prior_network_name = 'trrust_rawdata.human.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f6bb5-c403-4401-8c55-acbaa586d615",
   "metadata": {},
   "source": [
    "## True GI subtypes from GEARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5f578-d4f7-456b-8c23-4055a3376390",
   "metadata": {},
   "source": [
    "https://github.com/yhr91/GEARS_misc/blob/f88211870dfa89c38a2eedbd69ca1abd28a25f3c/gears/inference.py#L796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16486645-a536-41e8-a3eb-3aebfea23d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "GIs = {\n",
    "    'NEOMORPHIC': ['CBL+TGFBR2',\n",
    "                   'KLF1+TGFBR2',\n",
    "                   'MAP2K6+SPI1',\n",
    "                   'SAMD1+TGFBR2',\n",
    "                   'TGFBR2+C19orf26',\n",
    "                   'TGFBR2+ETS2',\n",
    "                   'CBL+UBASH3A',\n",
    "                   'CEBPE+KLF1',\n",
    "                   'DUSP9+MAPK1',\n",
    "                   'FOSB+PTPN12',\n",
    "                   'PLK4+STIL',\n",
    "                   'PTPN12+OSR2',\n",
    "                   'ZC3HAV1+CEBPE'],\n",
    "    'ADDITIVE': ['BPGM+SAMD1',\n",
    "                 'CEBPB+MAPK1',\n",
    "                 'CEBPB+OSR2',\n",
    "                 'DUSP9+PRTG',\n",
    "                 'FOSB+OSR2',\n",
    "                 'IRF1+SET',\n",
    "                 'MAP2K3+ELMSAN1',\n",
    "                 'MAP2K6+ELMSAN1',\n",
    "                 'POU3F2+FOXL2',\n",
    "                 'SAMD1+PTPN12',\n",
    "                 'SAMD1+UBASH3B',\n",
    "                 'SAMD1+ZBTB1',\n",
    "                 'SGK1+TBX2',\n",
    "                 'TBX3+TBX2',\n",
    "                 'ZBTB10+SNAI1'],\n",
    "    'EPISTASIS': ['AHR+KLF1',\n",
    "                  'MAPK1+TGFBR2',\n",
    "                  'TGFBR2+IGDCC3',\n",
    "                  'TGFBR2+PRTG',\n",
    "                  'UBASH3B+OSR2',\n",
    "                  'DUSP9+ETS2',\n",
    "                  'KLF1+CEBPA',\n",
    "                  'MAP2K6+IKZF3',\n",
    "                  'ZC3HAV1+CEBPA'],\n",
    "    'REDUNDANT': ['CDKN1C+CDKN1A',\n",
    "                  'MAP2K3+MAP2K6',\n",
    "                  'CEBPB+CEBPA',\n",
    "                  'CEBPE+CEBPA',\n",
    "                  'CEBPE+SPI1',\n",
    "                  'ETS2+MAPK1',\n",
    "                  'FOSB+CEBPE',\n",
    "                  'FOXA3+FOXA1'],\n",
    "    'SYNERGY': ['CNN1+UBASH3A',\n",
    "                'ETS2+MAP7D1',\n",
    "                'FEV+CBFA2T3',\n",
    "                'FEV+ISL2',\n",
    "                'FEV+MAP7D1',\n",
    "                'PTPN12+UBASH3A',\n",
    "                'CBL+CNN1',\n",
    "                'CBL+PTPN12',\n",
    "                'CBL+PTPN9',\n",
    "                'CBL+UBASH3B',\n",
    "                'FOXA3+FOXL2',\n",
    "                'FOXA3+HOXB9',\n",
    "                'FOXL2+HOXB9',\n",
    "                'UBASH3B+CNN1',\n",
    "                'UBASH3B+PTPN12',\n",
    "                'UBASH3B+PTPN9',\n",
    "                'UBASH3B+ZBTB25',\n",
    "                'AHR+FEV',\n",
    "                'DUSP9+SNAI1',\n",
    "                'FOXA1+FOXF1',\n",
    "                'FOXA1+FOXL2',\n",
    "                'FOXA1+HOXB9',\n",
    "                'FOXF1+FOXL2',\n",
    "                'FOXF1+HOXB9',\n",
    "                'FOXL2+MEIS1',\n",
    "                'IGDCC3+ZBTB25',\n",
    "                'POU3F2+CBFA2T3',\n",
    "                'PTPN12+ZBTB25',\n",
    "                'SNAI1+DLX2',\n",
    "                'SNAI1+UBASH3B'],\n",
    "    'SUPPRESSOR': ['CEBPB+PTPN12',\n",
    "                   'CEBPE+CNN1',\n",
    "                   'CEBPE+PTPN12',\n",
    "                   'CNN1+MAPK1',\n",
    "                   'ETS2+CNN1',\n",
    "                   'ETS2+IGDCC3',\n",
    "                   'ETS2+PRTG',\n",
    "                   'FOSB+UBASH3B',\n",
    "                   'IGDCC3+MAPK1',\n",
    "                   'LYL1+CEBPB',\n",
    "                   'MAPK1+PRTG',\n",
    "                   'PTPN12+SNAI1']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b907c13-85fb-48d6-a829-1c25772f472c",
   "metadata": {},
   "source": [
    "## Define functions to calculate GI scores and cutoffs of each subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd547ef-03af-4fb9-b6a6-d587fa74fc82",
   "metadata": {},
   "source": [
    "GI scores include: Magnitude(mag), Model fit(corr_fit), Equality of contribution(eq_contr) and Similarity(dcor), they are from a trained TheilSenRegressor using expression after perturbation A, B and A+B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff741e1b-8ad6-4516-9055-4f9513e7561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_GIs(first_expr, second_expr, double_expr):\n",
    "    from sklearn.linear_model import TheilSenRegressor\n",
    "    from dcor import distance_correlation\n",
    "    singles_expr = np.array([first_expr, second_expr]).T\n",
    "    first_expr = first_expr.T\n",
    "    second_expr = second_expr.T\n",
    "    double_expr = double_expr.T\n",
    "    results = {}\n",
    "    results['ts'] = TheilSenRegressor(fit_intercept=False,\n",
    "                                      max_subpopulation=1e5,\n",
    "                                      max_iter=1000,\n",
    "                                      random_state=1000)\n",
    "    X = singles_expr\n",
    "    y = double_expr\n",
    "    results['ts'].fit(X, y.ravel())\n",
    "    Zts = results['ts'].predict(X)\n",
    "    results['c1'] = results['ts'].coef_[0]\n",
    "    results['c2'] = results['ts'].coef_[1]\n",
    "    results['mag'] = np.sqrt((results['c1'] ** 2 + results['c2'] ** 2))\n",
    "    results['dcor'] = distance_correlation(singles_expr, double_expr)\n",
    "    results['dcor_singles'] = distance_correlation(first_expr, second_expr)\n",
    "    results['dcor_first'] = distance_correlation(first_expr, double_expr)\n",
    "    results['dcor_second'] = distance_correlation(second_expr, double_expr)\n",
    "    results['corr_fit'] = np.corrcoef(Zts.flatten(), double_expr.flatten())[0, 1]\n",
    "    results['dominance'] = np.abs(np.log10(results['c1'] / results['c2']))\n",
    "    results['eq_contr'] = np.min([results['dcor_first'], results['dcor_second']]) / np.max(\n",
    "        [results['dcor_first'], results['dcor_second']])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be32bfa1-b73a-4cfb-a270-cffefe8a4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff(data_path, norman_adata, TFs, nonTFs, GIs):\n",
    "    norman_adata_nonTF = norman_adata[:, np.isin(norman_adata.var['gene_name'], nonTFs)]\n",
    "    GI_cutoff_df = pd.DataFrame(columns=['key', 'value'])\n",
    "    for key, values in GIs.items():\n",
    "        temp_df = pd.DataFrame({'key': [key] * len(values), 'value': values})\n",
    "        GI_cutoff_df = pd.concat([GI_cutoff_df, temp_df], ignore_index=True)\n",
    "    GI_cutoff_df.set_index('value', inplace=True)\n",
    "    GI_cutoff_df[['SSA', 'RED', 'NEO', 'EPI']] = None\n",
    "    for GItype, ABarray in GIs.items():\n",
    "        for AB in ABarray:\n",
    "            ctrl = np.squeeze(\n",
    "                np.array(norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == 'ctrl', :].X.todense().mean(0)))\n",
    "            truthA = np.squeeze(np.array(\n",
    "                norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == AB.split('+')[0] + '+ctrl',\n",
    "                :].X.todense().mean(\n",
    "                    0)))\n",
    "            truthB = np.squeeze(np.array(\n",
    "                norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == AB.split('+')[1] + '+ctrl',\n",
    "                :].X.todense().mean(\n",
    "                    0)))\n",
    "            truthAB = np.squeeze(\n",
    "                np.array(norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == AB, :].X.todense().mean(0)))\n",
    "            results = calculate_GIs(truthA - ctrl, truthB - ctrl, truthAB - ctrl)\n",
    "            GI_cutoff_df.at[AB, 'SSA'] = results['mag']\n",
    "            GI_cutoff_df.at[AB, 'RED'] = results['dcor']\n",
    "            GI_cutoff_df.at[AB, 'NEO'] = results['corr_fit']\n",
    "            GI_cutoff_df.at[AB, 'EPI'] = results['eq_contr']\n",
    "    thresh = {'SYNERGY': GI_cutoff_df.loc[GI_cutoff_df['key'] == 'SYNERGY', 'SSA'].min(),\n",
    "              'SUPPRESSOR': GI_cutoff_df.loc[GI_cutoff_df['key'] == 'SUPPRESSOR', 'SSA'].max(),\n",
    "              'ADDITIVE': [GI_cutoff_df.loc[GI_cutoff_df['key'] == 'ADDITIVE', 'SSA'].min(),\n",
    "                           GI_cutoff_df.loc[GI_cutoff_df['key'] == 'ADDITIVE', 'SSA'].max()],\n",
    "              'NEOMORPHIC': GI_cutoff_df.loc[GI_cutoff_df['key'] == 'NEOMORPHIC', 'NEO'].max(),\n",
    "              'EPISTASIS': GI_cutoff_df.loc[GI_cutoff_df['key'] == 'EPISTASIS', 'EPI'].max(),\n",
    "              'REDUNDANT': GI_cutoff_df.loc[GI_cutoff_df['key'] == 'REDUNDANT', 'RED'].min()}\n",
    "    from collections import defaultdict\n",
    "    GI_cutoff_dict = defaultdict(list)\n",
    "    for idx, row in GI_cutoff_df.iterrows():\n",
    "        GI_cutoff_dict[row['key']].append(idx)\n",
    "    GI_cutoff_dict = dict(GI_cutoff_dict)\n",
    "    return thresh, GI_cutoff_df, GI_cutoff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7685ad-f52c-40e6-a206-193b5d70c5dc",
   "metadata": {},
   "source": [
    "## GEARS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b557b5-e022-4a65-9a4b-f32fe7bda2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gears(data_path, pairs_to_pert_GI_GT):\n",
    "    if os.path.exists(os.path.join(data_path, 'GEARS_pred_pert_down_1012.pickle')):\n",
    "        with open(os.path.join(data_path, \"GEARS_pred_pert_down_1012.pickle\"), \"rb\") as file:\n",
    "            GEARS_pred_pert_down = pickle.load(file)\n",
    "        return GEARS_pred_pert_down\n",
    "        \n",
    "    GEARS_pred_pert_down = {}\n",
    "    from gears import PertData, GEARS\n",
    "    for combo in pairs_to_pert_GI_GT.keys():\n",
    "        pertA = combo.split('+')[0]\n",
    "        pertB = combo.split('+')[1]\n",
    "        pert_data = PertData(data_path=data_path, gene_set_path=os.path.join(data_path, 'essential_all_data_pert_genes.pkl'))\n",
    "        pert_data.load(data_path=data_path)\n",
    "        pert_data.prepare_split(test_perts=combo, seed=1)\n",
    "        pert_data.get_dataloader(batch_size=32, test_batch_size=128)\n",
    "        gears_model = GEARS(pert_data, device='cuda:0', weight_bias_track=False)\n",
    "\n",
    "        # gears_model.model_initialize(hidden_size=64)\n",
    "        # gears_model.train(epochs=20, lr=1e-4)\n",
    "        # os.makedirs(os.path.join(data_path, 'gears_model_GI', combo), exist_ok=True)\n",
    "        # gears_model.save_model(os.path.join(data_path, 'gears_model_GI', combo))\n",
    "\n",
    "        gears_model.load_pretrained(os.path.join(data_path, 'gears_model_GI', combo))\n",
    "\n",
    "        GEARS_pred_pert_down[combo] = {}\n",
    "        GEARS_pred_pert_down[combo][combo] = list(gears_model.predict([combo.split('+')]).values())[0]\n",
    "        GEARS_pred_pert_down[combo][pertA] = list(gears_model.predict([[pertA]]).values())[0]\n",
    "        GEARS_pred_pert_down[combo][pertB] = list(gears_model.predict([[pertB]]).values())[0]\n",
    "    with open(os.path.join(data_path, \"GEARS_pred_pert_down_1012.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(GEARS_pred_pert_down, file)\n",
    "    return GEARS_pred_pert_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efefd3-7e96-486e-8a49-744e106b2f97",
   "metadata": {},
   "source": [
    "## CPA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fccf4d-eb08-40fc-b983-5e369149127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpa(data_path, norman_adata, pairs_to_pert_GI_GT):\n",
    "    if os.path.exists(os.path.join(data_path, 'cpa_pred_pert_down_1012.pickle')):\n",
    "        with open(os.path.join(data_path, \"cpa_pred_pert_down_1012.pickle\"), \"rb\") as file:\n",
    "            cpa_pred_pert_down = pickle.load(file)\n",
    "        return cpa_pred_pert_down\n",
    "\n",
    "    def run_cpa_model(data_path, norman_adata, pairs_to_pert_GI_GT):\n",
    "        import cpa\n",
    "        model_params = {\n",
    "            \"n_latent\": 32,\n",
    "            \"recon_loss\": \"nb\",\n",
    "            \"doser_type\": \"linear\",\n",
    "            \"n_hidden_encoder\": 256,\n",
    "            \"n_layers_encoder\": 4,\n",
    "            \"n_hidden_decoder\": 256,\n",
    "            \"n_layers_decoder\": 2,\n",
    "            \"use_batch_norm_encoder\": True,\n",
    "            \"use_layer_norm_encoder\": False,\n",
    "            \"use_batch_norm_decoder\": False,\n",
    "            \"use_layer_norm_decoder\": False,\n",
    "            \"dropout_rate_encoder\": 0.2,\n",
    "            \"dropout_rate_decoder\": 0.0,\n",
    "            \"variational\": False,\n",
    "            \"seed\": 8206,\n",
    "        }\n",
    "        trainer_params = {\n",
    "            \"n_epochs_kl_warmup\": None,\n",
    "            \"n_epochs_adv_warmup\": 50,\n",
    "            \"n_epochs_mixup_warmup\": 10,\n",
    "            \"n_epochs_pretrain_ae\": 10,\n",
    "            \"mixup_alpha\": 0.1,\n",
    "            \"lr\": 0.0001,\n",
    "            \"wd\": 3.2170178270865573e-06,\n",
    "            \"adv_steps\": 3,\n",
    "            \"reg_adv\": 10.0,\n",
    "            \"pen_adv\": 20.0,\n",
    "            \"adv_lr\": 0.0001,\n",
    "            \"adv_wd\": 7.051355554517135e-06,\n",
    "            \"n_layers_adv\": 2,\n",
    "            \"n_hidden_adv\": 128,\n",
    "            \"use_batch_norm_adv\": True,\n",
    "            \"use_layer_norm_adv\": False,\n",
    "            \"dropout_rate_adv\": 0.3,\n",
    "            \"step_size_lr\": 25,\n",
    "            \"do_clip_grad\": False,\n",
    "            \"adv_loss\": \"cce\",\n",
    "            \"gradient_clip_value\": 5.0,\n",
    "        }\n",
    "        cpa_pred_pert_down = {}\n",
    "        combos = list(pairs_to_pert_GI_GT.keys())\n",
    "        for combo in combos:\n",
    "            norman_adata_cpa = norman_adata.copy()\n",
    "            norman_adata_cpa.obs['condition'] = pd.Categorical(norman_adata_cpa.obs['condition'])\n",
    "            norman_adata_cpa.obs['split'] = 'train'\n",
    "            norman_adata_cpa.obs.loc[norman_adata_cpa.obs['condition'] == combo, 'split'] = 'ood'\n",
    "            train_indices = norman_adata_cpa.obs[norman_adata_cpa.obs['split'] == 'train'].index\n",
    "            validation_size = int(0.1 * len(train_indices))\n",
    "            random_train_indices = np.random.choice(train_indices, size=validation_size, replace=False)\n",
    "            norman_adata_cpa.obs.loc[random_train_indices, 'split'] = 'validation'\n",
    "            cpa.CPA.setup_anndata(norman_adata_cpa,\n",
    "                                  perturbation_key='condition',\n",
    "                                  control_group='ctrl',\n",
    "                                  dosage_key='dose_val',\n",
    "                                  categorical_covariate_keys=['cell_type'],\n",
    "                                  is_count_data=False,\n",
    "                                  deg_uns_key='rank_genes_groups_cov',\n",
    "                                  deg_uns_cat_key='condition_name',\n",
    "                                  max_comb_len=2,\n",
    "                                  )\n",
    "            cpa_model = cpa.CPA(adata=norman_adata_cpa,\n",
    "                        split_key='split',\n",
    "                        train_split='train',\n",
    "                        valid_split='valid',\n",
    "                        test_split='ood',\n",
    "                        **model_params,\n",
    "                       )\n",
    "            cpa_model.train(max_epochs=2000,\n",
    "                    use_gpu=True,\n",
    "                    batch_size=2048,\n",
    "                    plan_kwargs=trainer_params,\n",
    "                    early_stopping_patience=5,\n",
    "                    check_val_every_n_epoch=5,\n",
    "                    save_path=os.path.join(data_path, 'CPA_model', combo)\n",
    "                   )\n",
    "            norman_adata_cpa.layers['truth'] = norman_adata_cpa.X.copy()\n",
    "            ctrl_adata = norman_adata_cpa[norman_adata_cpa.obs['condition'] == 'ctrl'].copy()\n",
    "            norman_adata_cpa.X = ctrl_adata.X[np.random.choice(ctrl_adata.n_obs, size=norman_adata_cpa.n_obs, replace=True), :]\n",
    "            cpa_model.predict(norman_adata_cpa, batch_size=2048)\n",
    "            norman_adata_cpa.layers['CPA_pred'] = norman_adata_cpa.obsm['CPA_pred'].copy()\n",
    "            subset_indices = norman_adata_cpa.obs['condition'] == combo\n",
    "            cpa_pred = norman_adata_cpa.layers['CPA_pred'][subset_indices, :].mean(0)\n",
    "            cpa_pred_pert_down[combo] = {}\n",
    "            cpa_pred_pert_down[combo][combo] = cpa_pred\n",
    "            pertA = combo.split('+')[0]\n",
    "            pertB = combo.split('+')[1]\n",
    "            cpa_pred_pert_down[combo][pertA] = norman_adata_cpa.layers['CPA_pred'][\n",
    "                                               norman_adata_cpa.obs['condition'] == pertA + '+ctrl', :].mean(0)\n",
    "            cpa_pred_pert_down[combo][pertB] = norman_adata_cpa.layers['CPA_pred'][\n",
    "                                               norman_adata_cpa.obs['condition'] == pertB + '+ctrl', :].mean(0)\n",
    "\n",
    "        with open(os.path.join(data_path, \"cpa_pred_pert_down_1012.pickle\"), \"wb\") as file:\n",
    "            pickle.dump(cpa_pred_pert_down, file)\n",
    "    run_cpa_model(data_path, norman_adata, pairs_to_pert_GI_GT)\n",
    "    with open(os.path.join(data_path, \"cpa_pred_pert_down_1012.pickle\"), \"rb\") as file:\n",
    "        cpa_pred_pert_down = pickle.load(file)\n",
    "    return cpa_pred_pert_down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c33ee-5e21-488a-901d-d5f83a777014",
   "metadata": {},
   "source": [
    "## Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64563640-209e-4173-9410-7a37189740dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ct(data_path, norman_adata, pairs_to_pert_GI_GT, TFs, nonTFs):\n",
    "    if os.path.exists(os.path.join(data_path, 'CauTrigger_pred_pert_1012.pickle')):\n",
    "        with open(os.path.join(data_path, \"CauTrigger_pred_pert_1012.pickle\"), \"rb\") as file:\n",
    "            CauTrigger_pred_pert_up, CauTrigger_pred_pert_down, CauTrigger_pred_pert_all = pickle.load(file)\n",
    "        return CauTrigger_pred_pert_up, CauTrigger_pred_pert_down, CauTrigger_pred_pert_all\n",
    "        \n",
    "    from CauTrigger.model import CauTrigger\n",
    "    from CauTrigger.utils import set_seed\n",
    "    norman_adata_TF = norman_adata[:, np.isin(norman_adata.var['gene_name'], TFs)]\n",
    "    norman_adata_nonTF = norman_adata[:, np.isin(norman_adata.var['gene_name'], nonTFs)]\n",
    "    norman_adata_TF_ctrl = norman_adata_TF[norman_adata_TF.obs['condition'] == 'ctrl', :]\n",
    "    norman_adata_nonTF_ctrl = norman_adata_nonTF[norman_adata_nonTF.obs['condition'] == 'ctrl', :]\n",
    "    norman_adata_for_CT_ctrl = norman_adata_TF_ctrl.copy()\n",
    "    norman_adata_for_CT_ctrl.obsm['X_down'] = norman_adata_nonTF_ctrl.X.copy()\n",
    "    CauTrigger_pred_pert_up = {}\n",
    "    CauTrigger_pred_pert_down = {}\n",
    "    CauTrigger_pred_pert_all = {}\n",
    "    pairs_to_pert = list(pairs_to_pert_GI_GT.keys())\n",
    "    for pair_to_pert in pairs_to_pert:\n",
    "        pertAB = pair_to_pert\n",
    "        pertA = pair_to_pert.split('+')[0]\n",
    "        pertB = pair_to_pert.split('+')[1]\n",
    "        norman_adata_for_CT_pert = norman_adata_TF[\n",
    "                                   norman_adata_TF.obs['condition'].isin([pertA + '+ctrl', pertB + '+ctrl']), :]\n",
    "        norman_adata_for_CT_pert.obsm['X_down'] = norman_adata_nonTF[norman_adata_nonTF.obs['condition'].isin(\n",
    "            [pertA + '+ctrl', pertB + '+ctrl']), :].X.todense()\n",
    "        norman_adata_for_CT_ctrl1 = norman_adata_for_CT_ctrl[np.random.choice(norman_adata_for_CT_ctrl.n_obs, size=norman_adata_for_CT_pert.n_obs, replace=False), :]\n",
    "        adata_for_train = anndata.concat([norman_adata_for_CT_ctrl1, norman_adata_for_CT_pert])\n",
    "        adata_for_train.X = adata_for_train.X.todense()\n",
    "        adata_for_train.obs['labels'] = np.repeat([0, 1],\n",
    "                                                  [norman_adata_for_CT_ctrl1.n_obs, norman_adata_for_CT_pert.n_obs])\n",
    "        adata_for_train.obsm['X_down'] = adata_for_train.obsm['X_down'].todense()\n",
    "        set_seed(42)\n",
    "        model = CauTrigger(\n",
    "            adata_for_train,\n",
    "            n_causal=2,\n",
    "            n_latent=10,\n",
    "            n_hidden=128,\n",
    "            n_layers_encoder=0,\n",
    "            n_layers_decoder=0,\n",
    "            n_layers_dpd=0,\n",
    "            dropout_rate_encoder=0.1,\n",
    "            dropout_rate_decoder=0.1,\n",
    "            dropout_rate_dpd=0.1,\n",
    "            use_batch_norm='none',\n",
    "            use_batch_norm_dpd=True,\n",
    "            decoder_linear=True,\n",
    "            dpd_linear=False,\n",
    "            init_weight=None,\n",
    "            init_thresh=0.0,\n",
    "            update_down_weight=False,\n",
    "            attention=False,\n",
    "            att_mean=False,\n",
    "        )\n",
    "        weight_scheme = {'stage1': [0.1, 2.0, 2.0, 0.01, 0.5, 1.0, 0.0, 0.0, 0.0],\n",
    "                         'stage2': [0.4, 2.0, 2.0, 0.1, 0.5, 0.5, 0.0, 0.01, 0.01],\n",
    "                         'stage3': [0.8, 2.0, 2.0, 0.1, 0.1, 0.1, 1.0, 0.1, 0.1],\n",
    "                         'stage4': [1, 2.0, 2.0, 0.01, 0.01, 0.01, 1.0, 1.0, 1.0]}\n",
    "        if adata_for_train.shape[0] > 2000:\n",
    "            max_epochs = 100\n",
    "        else:\n",
    "            max_epochs = 200\n",
    "        model.train(max_epochs=max_epochs, im_factor=1, weight_scheme='norman')\n",
    "        norman_adata_for_CT_ctrl_testAB = norman_adata_for_CT_ctrl1.copy()\n",
    "        norman_adata_for_CT_ctrl_testAB.X[:,\n",
    "        norman_adata_for_CT_ctrl_testAB.var['gene_name'] == pertA] = 2 * norman_adata_for_CT_ctrl1.X.max()\n",
    "        norman_adata_for_CT_ctrl_testAB.X[:,\n",
    "        norman_adata_for_CT_ctrl_testAB.var['gene_name'] == pertB] = 2 * norman_adata_for_CT_ctrl1.X.max()\n",
    "        norman_adata_for_CT_ctrl_testA = norman_adata_for_CT_ctrl1.copy()\n",
    "        norman_adata_for_CT_ctrl_testA.X[:,\n",
    "        norman_adata_for_CT_ctrl_testA.var['gene_name'] == pertA] = 2 * norman_adata_for_CT_ctrl1.X.max()\n",
    "        norman_adata_for_CT_ctrl_testB = norman_adata_for_CT_ctrl1.copy()\n",
    "        norman_adata_for_CT_ctrl_testB.X[:,\n",
    "        norman_adata_for_CT_ctrl_testB.var['gene_name'] == pertB] = 2 * norman_adata_for_CT_ctrl1.X.max()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model_outputAB = model.module.forward(\n",
    "                torch.Tensor(norman_adata_for_CT_ctrl_testAB.X.todense()).to('cuda:0'))\n",
    "            model_outputA = model.module.forward(\n",
    "                torch.Tensor(norman_adata_for_CT_ctrl_testA.X.todense()).to('cuda:0'))\n",
    "            model_outputB = model.module.forward(\n",
    "                torch.Tensor(norman_adata_for_CT_ctrl_testB.X.todense()).to('cuda:0'))\n",
    "        pred_up = model_outputAB['x_up_rec1'].cpu().numpy().mean(0)\n",
    "        pred_down = model_outputAB['x_down_rec_alpha'].cpu().numpy().mean(0)\n",
    "        pred_all = np.concatenate([pred_up, pred_down], )\n",
    "        CauTrigger_pred_pert_up[pair_to_pert] = {}\n",
    "        CauTrigger_pred_pert_up[pair_to_pert][pair_to_pert] = pred_up\n",
    "        CauTrigger_pred_pert_up[pair_to_pert][pertA] = model_outputA['x_up_rec1'].cpu().numpy().mean(0)\n",
    "        CauTrigger_pred_pert_up[pair_to_pert][pertB] = model_outputB['x_up_rec1'].cpu().numpy().mean(0)\n",
    "        CauTrigger_pred_pert_down[pair_to_pert] = {}\n",
    "        CauTrigger_pred_pert_down[pair_to_pert][pair_to_pert] = pred_down\n",
    "        CauTrigger_pred_pert_down[pair_to_pert][pertA] = model_outputA['x_down_rec_alpha'].cpu().numpy().mean(0)\n",
    "        CauTrigger_pred_pert_down[pair_to_pert][pertB] = model_outputB['x_down_rec_alpha'].cpu().numpy().mean(0)\n",
    "        CauTrigger_pred_pert_all[pair_to_pert] = {}\n",
    "        CauTrigger_pred_pert_all[pair_to_pert][pair_to_pert] = pred_all\n",
    "        CauTrigger_pred_pert_all[pair_to_pert][pertA] = np.concatenate([model_outputA['x_up_rec1'].cpu().numpy().mean(0), model_outputA['x_down_rec_alpha'].cpu().numpy().mean(0)])\n",
    "        CauTrigger_pred_pert_all[pair_to_pert][pertB] = np.concatenate([model_outputB['x_up_rec1'].cpu().numpy().mean(0), model_outputB['x_down_rec_alpha'].cpu().numpy().mean(0)])\n",
    "    with open(os.path.join(data_path, \"CauTrigger_pred_pert_1012.pickle\"), \"wb\") as file:\n",
    "        pickle.dump((CauTrigger_pred_pert_up, CauTrigger_pred_pert_down, CauTrigger_pred_pert_all), file)\n",
    "    return CauTrigger_pred_pert_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72cf64-44fa-403d-a71f-2b8f44a529dc",
   "metadata": {},
   "source": [
    "## Run and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a0e87-36a0-43aa-acff-73e6ad608238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(data_path, output_path, data_name, prior_network_name, GIs):\n",
    "    norman_adata = sc.read_h5ad(os.path.join(data_path, data_name))\n",
    "    norman_adata = norman_adata[~norman_adata.obs['condition'].isin(\n",
    "        ['RHOXF2BB+ctrl', 'LYL1+IER5L', 'ctrl+IER5L', 'KIAA1804+ctrl', 'IER5L+ctrl', 'RHOXF2BB+ZBTB25',\n",
    "         'RHOXF2BB+SET']), :]\n",
    "    conditions = np.unique(norman_adata.obs['condition'])\n",
    "    pairs = conditions\n",
    "    valid_pairs = {\n",
    "        (min(pair, reversed_pair), max(pair, reversed_pair))\n",
    "        for pair in pairs if '+' in pair\n",
    "        for reversed_pair in ['+'.join(reversed(pair.split('+')))]\n",
    "        if reversed_pair in pairs\n",
    "    }\n",
    "    unique_valid_pairs = list(valid_pairs)\n",
    "    df = norman_adata.obs.copy()\n",
    "    condition_map = {pair[0]: pair[0] for pair in unique_valid_pairs}\n",
    "    condition_map.update({pair[1]: pair[0] for pair in unique_valid_pairs})\n",
    "    df['condition'] = df['condition'].replace(condition_map)\n",
    "    df['condition_name'] = df['condition'].apply(lambda x: f'K562_{x}_1+1' if x != 'ctrl' else x)\n",
    "    norman_adata.obs = df.copy()\n",
    "    norman_adata.obs['condition'] = norman_adata.obs['condition'].astype(str)\n",
    "    norman_adata.obs['condition'] = pd.Categorical(norman_adata.obs['condition'],\n",
    "                                                   categories=norman_adata.obs['condition'].unique())\n",
    "    conditions = np.unique(norman_adata.obs['condition'])\n",
    "    conditions = np.delete(conditions, np.where(conditions == 'ctrl'))\n",
    "    conditions_gene = []\n",
    "    _ = [conditions_gene.extend(s.split('+')) for s in conditions]\n",
    "    conditions_gene = list(set(conditions_gene))\n",
    "    conditions_gene.remove('ctrl')\n",
    "    Trrust = pd.read_table(os.path.join(data_path, prior_network_name), header=None)\n",
    "    Trrust_TF = Trrust.iloc[:, 0].dropna().unique()\n",
    "    Trrust_nonTF = np.setdiff1d(Trrust.iloc[:, 1].dropna().unique(), Trrust_TF)\n",
    "    TFs = np.intersect1d(Trrust_TF, norman_adata.var['gene_name'])\n",
    "    nonTFs = np.intersect1d(Trrust_nonTF, norman_adata.var['gene_name'])\n",
    "    TFs_to_pert = np.intersect1d(TFs, conditions_gene)\n",
    "    pairs_to_pert = [condition for condition in conditions if\n",
    "                     condition.split('+')[0] in TFs_to_pert and condition.split('+')[1] in TFs_to_pert]\n",
    "    pairs_to_pert_GI_GT = {val: key for key, values in GIs.items() for val in values if val in pairs_to_pert}\n",
    "    reverse_pairs_to_pert_GI_GT = {}\n",
    "    for pair, interaction in pairs_to_pert_GI_GT.items():\n",
    "        if interaction not in reverse_pairs_to_pert_GI_GT:\n",
    "            reverse_pairs_to_pert_GI_GT[interaction] = []\n",
    "        reverse_pairs_to_pert_GI_GT[interaction].append(pair)\n",
    "    CauTrigger_pred_pert_up, CauTrigger_pred_pert_down, CauTrigger_pred_pert_all = run_ct(data_path, norman_adata, pairs_to_pert_GI_GT, TFs, nonTFs)\n",
    "    GEARS_pred_pert_all = run_gears(data_path, pairs_to_pert_GI_GT)\n",
    "    cpa_pred_pert_all = run_cpa(data_path, norman_adata, pairs_to_pert_GI_GT)\n",
    "    thresh, GI_cutoff_df, GI_cutoff_dict = get_cutoff(data_path, norman_adata, TFs, nonTFs, reverse_pairs_to_pert_GI_GT)\n",
    "    GI_results_df = pd.DataFrame.from_dict(pairs_to_pert_GI_GT, orient='index', columns=['value'])\n",
    "    GI_results_df[['SSA', 'RED', 'NEO', 'EPI']] = None\n",
    "    for pair_to_pert in pairs_to_pert_GI_GT.keys():\n",
    "        GI_results_df.at[pair_to_pert, 'SSA'] = GI_cutoff_df.loc[pair_to_pert, 'SSA']\n",
    "        GI_results_df.at[pair_to_pert, 'RED'] = GI_cutoff_df.loc[pair_to_pert, 'RED']\n",
    "        GI_results_df.at[pair_to_pert, 'NEO'] = GI_cutoff_df.loc[pair_to_pert, 'NEO']\n",
    "        GI_results_df.at[pair_to_pert, 'EPI'] = GI_cutoff_df.loc[pair_to_pert, 'EPI']\n",
    "    down_index = norman_adata.var.index[norman_adata.var.gene_name.isin(nonTFs)]\n",
    "    ctrl = np.array(norman_adata[norman_adata.obs['condition'] == 'ctrl', down_index].X.mean(0)).flatten()\n",
    "    GI_results_df[['SSA_ct', 'RED_ct', 'NEO_ct', 'EPI_ct']] = None\n",
    "    for pair_to_pert in pairs_to_pert_GI_GT.keys():\n",
    "        pertA = pair_to_pert.split('+')[0]\n",
    "        pertB = pair_to_pert.split('+')[1]\n",
    "        first = CauTrigger_pred_pert_down[pair_to_pert][pertA]\n",
    "        second = CauTrigger_pred_pert_down[pair_to_pert][pertB]\n",
    "        together = CauTrigger_pred_pert_down[pair_to_pert][pair_to_pert]\n",
    "        results = calculate_GIs(first-ctrl, second-ctrl, together-ctrl)\n",
    "        GI_results_df.at[pair_to_pert, 'SSA_ct'] = results['mag']\n",
    "        GI_results_df.at[pair_to_pert, 'RED_ct'] = results['dcor']\n",
    "        GI_results_df.at[pair_to_pert, 'NEO_ct'] = results['corr_fit']\n",
    "        GI_results_df.at[pair_to_pert, 'EPI_ct'] = results['eq_contr']\n",
    "    GI_results_df[['SSA_gears', 'RED_gears', 'NEO_gears', 'EPI_gears']] = None\n",
    "    for pair_to_pert in pairs_to_pert_GI_GT.keys():\n",
    "        pertA = pair_to_pert.split('+')[0]\n",
    "        pertB = pair_to_pert.split('+')[1]\n",
    "        first = GEARS_pred_pert_all[pair_to_pert][pertA][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        second = GEARS_pred_pert_all[pair_to_pert][pertB][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        together = GEARS_pred_pert_all[pair_to_pert][pair_to_pert][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        results = calculate_GIs(first-ctrl, second-ctrl, together-ctrl)\n",
    "        GI_results_df.at[pair_to_pert, 'SSA_gears'] = results['mag']\n",
    "        GI_results_df.at[pair_to_pert, 'RED_gears'] = results['dcor']\n",
    "        GI_results_df.at[pair_to_pert, 'NEO_gears'] = results['corr_fit']\n",
    "        GI_results_df.at[pair_to_pert, 'EPI_gears'] = results['eq_contr']\n",
    "    GI_results_df[['SSA_cpa', 'RED_cpa', 'NEO_cpa', 'EPI_cpa']] = None\n",
    "    for pair_to_pert in pairs_to_pert_GI_GT.keys():\n",
    "        pertA = pair_to_pert.split('+')[0]\n",
    "        pertB = pair_to_pert.split('+')[1]\n",
    "        first = cpa_pred_pert_all[pair_to_pert][pertA][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        second = cpa_pred_pert_all[pair_to_pert][pertB][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        together = cpa_pred_pert_all[pair_to_pert][pair_to_pert][norman_adata.var.gene_name.isin(nonTFs)]\n",
    "        results = calculate_GIs(first-ctrl, second-ctrl, together-ctrl)\n",
    "        GI_results_df.at[pair_to_pert, 'SSA_cpa'] = results['mag']\n",
    "        GI_results_df.at[pair_to_pert, 'RED_cpa'] = results['dcor']\n",
    "        GI_results_df.at[pair_to_pert, 'NEO_cpa'] = results['corr_fit']\n",
    "        GI_results_df.at[pair_to_pert, 'EPI_cpa'] = results['eq_contr']\n",
    "    GI_results_df.to_csv(os.path.join(output_path, 'GI_results_df.csv'))\n",
    "    GI_results_df2 = GI_results_df.iloc[:, [0] + list(range(5, 17))]\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'SYNERGY', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] = (\n",
    "            GI_results_df2.loc[\n",
    "                GI_results_df2['value'] == 'SYNERGY', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] >= thresh[\n",
    "                'SYNERGY']).astype(int)\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'SUPPRESSOR', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] = (\n",
    "            GI_results_df2.loc[\n",
    "                GI_results_df2['value'] == 'SUPPRESSOR', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] <= thresh[\n",
    "                'SUPPRESSOR']).astype(int)\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'ADDITIVE', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] = \\\n",
    "        (((GI_results_df2.loc[\n",
    "               GI_results_df2['value'] == 'ADDITIVE', ['SSA_gears', 'SSA_ct', 'SSA_cpa']] >=\n",
    "           thresh['ADDITIVE'][0]) & (GI_results_df2.loc[GI_results_df2['value'] == 'ADDITIVE',\n",
    "        ['SSA_gears', 'SSA_ct', 'SSA_cpa']] <= thresh['ADDITIVE'][1])).astype(int))\n",
    "    GI_results_df2.loc[GI_results_df2['value'].isin(['NEOMORPHIC', 'EPISTASIS', 'REDUNDANT']), ['SSA_gears', 'SSA_ct',\n",
    "                                                                                                'SSA_cpa']] = 0\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'NEOMORPHIC', ['NEO_gears', 'NEO_ct', 'NEO_cpa']] = (\n",
    "            GI_results_df2.loc[\n",
    "                GI_results_df2['value'] == 'NEOMORPHIC', ['NEO_gears', 'NEO_ct', 'NEO_cpa']] <= thresh[\n",
    "                'NEOMORPHIC']).astype(int)\n",
    "    GI_results_df2.loc[GI_results_df2['value'] != 'NEOMORPHIC', ['NEO_gears', 'NEO_ct', 'NEO_cpa']] = 0\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'EPISTASIS', ['EPI_gears', 'EPI_ct', 'EPI_cpa']] = (\n",
    "            GI_results_df2.loc[\n",
    "                GI_results_df2['value'] == 'EPISTASIS', ['EPI_gears', 'EPI_ct', 'EPI_cpa']] <= thresh[\n",
    "                'EPISTASIS']).astype(int)\n",
    "    GI_results_df2.loc[GI_results_df2['value'] != 'EPISTASIS', ['EPI_gears', 'EPI_ct', 'EPI_cpa']] = 0\n",
    "    GI_results_df2.loc[GI_results_df2['value'] == 'REDUNDANT', ['RED_gears', 'RED_ct', 'RED_cpa']] = (\n",
    "            GI_results_df2.loc[\n",
    "                GI_results_df2['value'] == 'REDUNDANT', ['RED_gears', 'RED_ct', 'RED_cpa']] >= thresh[\n",
    "                'REDUNDANT']).astype(int)\n",
    "    GI_results_df2.loc[GI_results_df2['value'] != 'REDUNDANT', ['RED_gears', 'RED_ct', 'RED_cpa']] = 0\n",
    "    GI_table = GI_results_df2[GI_results_df2.value.isin(['SYNERGY', 'REDUNDANT'])]\n",
    "    GI_table = GI_table.drop(GI_table.columns[0], axis=1)\n",
    "    new_columns = []\n",
    "    for i in range(0, len(GI_table.columns), 4):\n",
    "        new_column_name = f'combined_{i // 4}'\n",
    "        GI_table[new_column_name] = GI_table.iloc[:, i:i + 4].sum(axis=1)\n",
    "        new_columns.append(new_column_name)\n",
    "    GI_table.drop(GI_table.columns[:len(GI_table.columns) - len(new_columns)], axis=1, inplace=True)\n",
    "    GI_table = GI_table.rename(columns={'combined_0': 'CauTrigger', 'combined_1': 'GEARS', 'combined_2': 'CPA'})\n",
    "    GI_table['Type'] = GI_results_df2['value']\n",
    "    total_row = GI_table[['CauTrigger', 'GEARS', 'CPA']].sum()/17\n",
    "    GI_table = GI_table.groupby('Type').mean()\n",
    "    GI_table['Type'] = GI_table.index\n",
    "    GI_table = pd.melt(GI_table, id_vars=['Type'], var_name='Method', value_name='Score')\n",
    "    plt.figure()\n",
    "    sns.barplot(x='Type', y='Score', hue='Method', data=GI_table, palette=sns.color_palette()[3:6])\n",
    "    plt.title('')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(os.path.join(output_path, f'plot_ACC_cutoff_down.png'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_path, f'plot_ACC_cutoff_down.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335be47-7dea-4af7-a70a-4cb9c7216966",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark(data_path, output_path, data_name, prior_network_name, GIs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_CT",
   "language": "python",
   "name": "project_ct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
