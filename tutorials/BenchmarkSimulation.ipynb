{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513dc4eb-b85c-4dad-9936-90754c09ac9a",
   "metadata": {},
   "source": [
    "# Benchmark in simulation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1fa76d-d448-464f-be7a-66c610423b5e",
   "metadata": {},
   "source": [
    "## Import libraries and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6cc14-2950-49b2-8e20-57ba177a02e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T06:14:29.318104Z",
     "start_time": "2023-12-05T06:14:25.702859Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import (roc_curve, auc, confusion_matrix, accuracy_score, matthews_corrcoef, f1_score,\n",
    "                             precision_score, recall_score, precision_recall_curve)\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, Ridge\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import pearsonr, spearmanr, f_oneway, norm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "from CauTrigger.utils import set_seed\n",
    "from CauTrigger.model import CauTrigger\n",
    "from CauTrigger.dataloaders import generate_synthetic_jersey\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f21e5-386f-47ca-81bd-ba003758fcb4",
   "metadata": {},
   "source": [
    "## Set your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835c968-f6b4-44ce-85f7-f01ec740b2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T06:14:29.318104Z",
     "start_time": "2023-12-05T06:14:25.702859Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '/your/working/directory'\n",
    "case_path = os.path.join(BASE_DIR, 'BenchmarkSimulation/')\n",
    "data_path = os.path.join(case_path, 'data/')\n",
    "output_path = os.path.join(case_path, 'output/')\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208819d-4836-4231-844a-71b6d7fbbac3",
   "metadata": {},
   "source": [
    "## Define other methods and our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483f035a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T06:14:29.559737Z",
     "start_time": "2023-12-05T06:14:29.455769Z"
    },
    "code_folding": [
     1,
     32,
     63,
     217,
     304,
     330
    ]
   },
   "outputs": [],
   "source": [
    "# CauTrigger model\n",
    "def run_model(adata, max_epochs, init_weight=None):\n",
    "    set_seed(42)\n",
    "    adata1 = adata.copy()\n",
    "    model = CauTrigger(\n",
    "        adata1,\n",
    "        n_causal=2,\n",
    "        n_latent=10,\n",
    "        n_hidden=128,\n",
    "        n_layers_encoder=0,\n",
    "        n_layers_decoder=0,\n",
    "        n_layers_dpd=0,\n",
    "        dropout_rate_encoder=0.0,\n",
    "        dropout_rate_decoder=0.0,\n",
    "        dropout_rate_dpd=0.0,\n",
    "        use_batch_norm='none',\n",
    "        use_batch_norm_dpd=True,\n",
    "        decoder_linear=True,\n",
    "        dpd_linear=False,\n",
    "        init_weight=init_weight,\n",
    "        init_thresh=0.0,\n",
    "        update_down_weight=False,\n",
    "        attention=False,\n",
    "        att_mean=False,\n",
    "    )\n",
    "    model.train(max_epochs=max_epochs, stage_training=True)\n",
    "    weight_df_weight = model.get_up_feature_weights(normalize=True, method=\"Model\", sort_by_weight=False)\n",
    "    weight_df = pd.DataFrame({'weight_value': weight_df_weight[0]['weight'],})\n",
    "    return weight_df\n",
    "\n",
    "\n",
    "def gauss_ci_test(suff_stat, i, j, K):\n",
    "    corr_matrix = suff_stat[\"C\"]\n",
    "    n_samples = suff_stat[\"n\"]\n",
    "    if len(K) == 0:\n",
    "        r = corr_matrix[i, j]\n",
    "    elif len(K) == 1:\n",
    "        k = K[0]\n",
    "        r = (corr_matrix[i, j] - corr_matrix[i, k] * corr_matrix[j, k]) / math.sqrt(\n",
    "            (1 - corr_matrix[i, k] ** 2) * (1 - corr_matrix[j, k] ** 2)\n",
    "        )\n",
    "    else:\n",
    "        sub_corr = corr_matrix[np.ix_([i, j] + K, [i, j] + K)]\n",
    "        precision_matrix = np.linalg.pinv(sub_corr)\n",
    "        r = (-1 * precision_matrix[0, 1]) / math.sqrt(\n",
    "            abs(precision_matrix[0, 0] * precision_matrix[1, 1])\n",
    "        )\n",
    "    r = max(min(r, 0.99999), -0.99999)\n",
    "    z = 0.5 * math.log1p((2 * r) / (1 - r))\n",
    "    z_standard = z * math.sqrt(n_samples - len(K) - 3)\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_standard)))\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def get_neighbors(G, x, exclude_y):\n",
    "    return [i for i, connected in enumerate(G[x]) if connected and i != exclude_y]\n",
    "\n",
    "\n",
    "def skeleton(suff_stat, alpha):\n",
    "    p_value_mat = np.zeros_like(suff_stat[\"C\"])\n",
    "    n_nodes = suff_stat[\"C\"].shape[0]\n",
    "    O = [[[] for _ in range(n_nodes)] for _ in range(n_nodes)]\n",
    "    G = [[i != j for i in range(n_nodes)] for j in range(n_nodes)]\n",
    "    pairs = [(i, j) for i in range(n_nodes) for j in range(i+1, n_nodes)]\n",
    "    done = False\n",
    "    l = 0\n",
    "    while not done and any(any(row) for row in G):\n",
    "        done = True\n",
    "        for x, y in pairs:\n",
    "            if G[x][y]:\n",
    "                neighbors = get_neighbors(G, x, y)\n",
    "                if len(neighbors) >= l:\n",
    "                    done = False\n",
    "                    for K in combinations(neighbors, l):\n",
    "                        p_value = gauss_ci_test(suff_stat, x, y, list(K))\n",
    "                        if p_value > p_value_mat[x][y]:\n",
    "                            p_value_mat[x][y] = p_value_mat[y][x] = p_value\n",
    "                        if p_value >= alpha:\n",
    "                            G[x][y] = G[y][x] = False\n",
    "                            O[x][y] = O[y][x] = list(K)\n",
    "                            break\n",
    "        l += 1\n",
    "    return np.asarray(G, dtype=int), O, p_value_mat\n",
    "\n",
    "\n",
    "def extend_cpdag(G, O):\n",
    "    n_nodes = G.shape[0]\n",
    "    def rule1(g):\n",
    "        pairs = [(i, j) for i in range(n_nodes) for j in range(n_nodes) if g[i][j] == 1 and g[j][i] == 0]\n",
    "        for i, j in pairs:\n",
    "            all_k = [k for k in range(n_nodes) if (g[j][k] == 1 and g[k][j] == 1) and (g[i][k] == 0 and g[k][i] == 0)]\n",
    "            for k in all_k:\n",
    "                g[j][k] = 1\n",
    "                g[k][j] = 0\n",
    "        return g\n",
    "    def rule2(g):\n",
    "        pairs = [(i, j) for i in range(n_nodes) for j in range(n_nodes) if g[i][j] == 1 and g[j][i] == 1]\n",
    "        for i, j in pairs:\n",
    "            all_k = [k for k in range(n_nodes) if (g[i][k] == 1 and g[k][i] == 0) and (g[k][j] == 1 and g[j][k] == 0)]\n",
    "            if len(all_k) > 0:\n",
    "                g[i][j] = 1\n",
    "                g[j][i] = 0\n",
    "        return g\n",
    "    def rule3(g):\n",
    "        pairs = [(i, j) for i in range(n_nodes) for j in range(n_nodes) if g[i][j] == 1 and g[j][i] == 1]\n",
    "        for i, j in pairs:\n",
    "            all_k = [k for k in range(n_nodes) if (g[i][k] == 1 and g[k][i] == 1) and (g[k][j] == 1 and g[j][k] == 0)]\n",
    "            if len(all_k) >= 2:\n",
    "                for k1, k2 in combinations(all_k, 2):\n",
    "                    if g[k1][k2] == 0 and g[k2][k1] == 0:\n",
    "                        g[i][j] = 1\n",
    "                        g[j][i] = 0\n",
    "                        break\n",
    "        return g\n",
    "\n",
    "    pairs = [(i, j) for i in range(n_nodes) for j in range(n_nodes) if G[i][j] == 1]\n",
    "    for x, y in sorted(pairs, key=lambda x: (x[1], x[0])):\n",
    "        all_z = [z for z in range(n_nodes) if G[y][z] == 1 and z != x]\n",
    "        for z in all_z:\n",
    "            if G[x][z] == 0 and y not in O[x][z]:\n",
    "                G[x][y] = G[z][y] = 1\n",
    "                G[y][x] = G[y][z] = 0\n",
    "\n",
    "    old_G = np.zeros((n_nodes, n_nodes))\n",
    "    while not np.array_equal(old_G, G):\n",
    "        old_G = G.copy()\n",
    "        G = rule1(G)\n",
    "        G = rule2(G)\n",
    "        G = rule3(G)\n",
    "\n",
    "    return np.array(G)\n",
    "\n",
    "\n",
    "def pc(suff_stat, alpha=0.5, verbose=False):\n",
    "    G, O, pvm = skeleton(suff_stat, alpha)\n",
    "    cpdag = extend_cpdag(G, O)\n",
    "    if verbose:\n",
    "        print(cpdag)\n",
    "    return cpdag, pvm\n",
    "\n",
    "\n",
    "# PC algorithm model\n",
    "def run_pc(X, y):\n",
    "    alpha = 0.05\n",
    "    data = pd.DataFrame(np.column_stack((X, y)))\n",
    "    cpdag, pvm = pc(\n",
    "        suff_stat={\"C\": data.corr().values, \"n\": data.shape[0]},\n",
    "        alpha=alpha\n",
    "    )\n",
    "    pv = pvm[:-1, -1]\n",
    "    return 1 - pv\n",
    "\n",
    "\n",
    "# VAE model\n",
    "def run_VAE(X, y, n_hidden, n_latent):\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    n_features = X.shape[1]\n",
    "    features = torch.tensor(X, dtype=torch.float32)\n",
    "    labels = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    class VAE(nn.Module):\n",
    "        def __init__(self, num_features):\n",
    "            super().__init__()\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(num_features, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, 2 * n_latent),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(n_latent, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, num_features),\n",
    "            )\n",
    "            self.DPD = nn.Sequential(\n",
    "                nn.Linear(n_latent, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, 1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "        def reparameterize(self, mu, logvar):\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps * std + mu\n",
    "        def forward(self, x):\n",
    "            mu_logvar = self.encoder(x)\n",
    "            mu = mu_logvar[:, :n_latent]\n",
    "            logvar = mu_logvar[:, n_latent:]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            y = self.DPD(z)\n",
    "            reconstructed = self.decoder(z)\n",
    "            return reconstructed, y, mu, logvar\n",
    "    model = VAE(n_features)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    dpd_criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    re_losses = []\n",
    "    kl_losses = []\n",
    "    dpd_losses = []\n",
    "    for epoch in range(200):\n",
    "        for data, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, y_dpd, mu, logvar = model(data)\n",
    "            re_loss = recon_criterion(recon_batch, data)\n",
    "            re_losses.append(re_loss.item())\n",
    "            kl_loss = (\n",
    "                -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / data.shape[0]\n",
    "            )\n",
    "            kl_losses.append(kl_loss.item())\n",
    "            dpd_loss = dpd_criterion(y_dpd, targets)\n",
    "            dpd_losses.append(dpd_loss.item())\n",
    "            if epoch <= 100:\n",
    "                loss = re_loss + kl_loss * 0.1 + dpd_loss * 0.1\n",
    "            else:\n",
    "                loss = re_loss + kl_loss * 0.1 + dpd_loss * 0.1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "    model.eval()\n",
    "    features.requires_grad = True\n",
    "    _, y_prob, _, _ = model(features)\n",
    "    loss = dpd_criterion(y_prob, labels)\n",
    "    loss.backward()\n",
    "    grads = features.grad.abs()\n",
    "    grad_features_importance = grads.mean(dim=0)\n",
    "    grad_df = grad_features_importance.detach().numpy()\n",
    "    return grad_df\n",
    "\n",
    "\n",
    "# Other machine learning methods\n",
    "def run_ml_methods(adata):\n",
    "    set_seed(42)\n",
    "    adata1 = adata.copy()\n",
    "    X = adata1.X\n",
    "    y = adata1.obs['labels'].values\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    \n",
    "    # SVM\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X, y)\n",
    "    svm_importance = np.abs(svm.coef_)\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X, y)\n",
    "    rf_importance = rf.feature_importances_\n",
    "\n",
    "    # LASSO\n",
    "    lasso = LassoCV(cv=5)\n",
    "    lasso.fit(X, y)\n",
    "    lasso_importance = np.abs(lasso.coef_)\n",
    "\n",
    "    # Mutual Information\n",
    "    mi_importance = mutual_info_classif(X, y)\n",
    "\n",
    "    # Logistic Regression\n",
    "    logistic = LogisticRegression()\n",
    "    logistic.fit(X, y)\n",
    "    logistic_importance = np.abs(logistic.coef_)\n",
    "\n",
    "    # Pearson correlation\n",
    "    pearson_importance = np.abs([pearsonr(X[:, i], y)[0] for i in range(X.shape[1])])\n",
    "\n",
    "    # ANOVA\n",
    "    anova_importance = np.array([f_oneway(*(X[y == c][:, i] for c in np.unique(y)))[0] for i in range(X.shape[1])])\n",
    "\n",
    "    # PC\n",
    "    pc_importance = run_pc(X, y)\n",
    "\n",
    "    # VAE\n",
    "    vae_grad_importance = run_VAE(X, y, n_latent=10, n_hidden=64)\n",
    "\n",
    "    feature_importance = np.vstack(\n",
    "        (svm_importance, rf_importance, lasso_importance, mi_importance, logistic_importance, pearson_importance, anova_importance, pc_importance, vae_grad_importance))\n",
    "    normalized_feature_importance = normalize(feature_importance, norm='l1')\n",
    "    weight_df = pd.DataFrame(normalized_feature_importance.T,\n",
    "                             columns=['SVM', 'Random Forest', 'LASSO', 'Mutual Information', 'Logistic Regression',\n",
    "                                      'Pearson Correlation', 'ANOVA', 'PC Algorithm', 'VAE_Grad'])\n",
    "    weight_df.index = adata1.var_names\n",
    "    return weight_df\n",
    "\n",
    "\n",
    "def select_features(df, threshold=None, topk=None):\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = pd.DataFrame(df)\n",
    "    selected_features = []\n",
    "    for column in df.columns:\n",
    "        sorted_column = df[column].sort_values(ascending=False)\n",
    "        if threshold and not topk:\n",
    "            cum_sum = sorted_column.cumsum()\n",
    "            selected = (cum_sum <= threshold).astype(int)\n",
    "            if selected.sum() == 0:\n",
    "                selected[sorted_column.index[0]] = 1\n",
    "        elif topk:\n",
    "            top_k_features = sorted_column.nlargest(topk).index\n",
    "            selected = pd.Series(0, index=df.index)\n",
    "            selected[top_k_features] = 1\n",
    "        else:\n",
    "            raise ValueError('Please pass valid argument!')\n",
    "        selected = pd.Series(selected, name=column)\n",
    "        selected_features.append(selected)\n",
    "    selected_df = pd.concat(selected_features, axis=1)\n",
    "    selected_df.columns = df.columns\n",
    "    return selected_df.reindex(df.index)\n",
    "\n",
    "\n",
    "def generate_boxplot_csv(df, file_start_name='', subfolder_name='', set_ylim=True):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.boxplot(data=df, palette='Set2')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Methods')\n",
    "    plt.ylabel(f'{file_start_name}')\n",
    "    plt.title(f'{file_start_name} Boxplot for Different Methods')\n",
    "    plt.tight_layout()\n",
    "    if set_ylim:\n",
    "        plt.ylim(0, 1)\n",
    "    plt.savefig(os.path.join(subfolder_name, f'{file_start_name}_boxplot.pdf'), format='pdf')\n",
    "    plt.savefig(os.path.join(subfolder_name, f'{file_start_name}_boxplot.png'), format='png')\n",
    "    plt.close()\n",
    "    df = df.T\n",
    "    df['Mean'] = df.mean(axis=1)\n",
    "    df['Max'] = df.max(axis=1)\n",
    "    df['Min'] = df.min(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507e15f-73f7-4510-a4df-8243834f8a19",
   "metadata": {},
   "source": [
    "## Define the benchmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed164b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T06:14:29.756175Z",
     "start_time": "2023-12-05T06:14:29.561575Z"
    },
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "def run_benchmark(\n",
    "        n_dataset=10,\n",
    "        n_samples=200,\n",
    "        oversampling_factor=5,\n",
    "        max_epochs=400,\n",
    "        threshold=0.3,\n",
    "        topk=0,\n",
    "        noise_scale=0.1,\n",
    "        causal_strength=5,\n",
    "        is_linear=False,\n",
    "        n_up_features=50,\n",
    "        n_causal=10,\n",
    "        n_down_features=150,\n",
    "        init_weight=None,\n",
    "        resdir=None,\n",
    ") -> dict:\n",
    "    model_res_all = []\n",
    "    svm_result = []\n",
    "    rf_result = []\n",
    "    lasso_result = []\n",
    "    mi_result = []\n",
    "    lr_result = []\n",
    "    pearson_result = []\n",
    "    anova_result = []\n",
    "    pc_result = []\n",
    "    vae_grad_result = []\n",
    "    adata_dict = {}\n",
    "    for i in range(n_dataset):\n",
    "        print(f\"This is the {i + 1}/{n_dataset} dataset\")\n",
    "        set_seed(i)\n",
    "        adata = generate_synthetic_jersey(n_samples=n_samples,\n",
    "                                          oversampling_factor=oversampling_factor,\n",
    "                                           n_up_features=n_up_features,\n",
    "                                           n_down_features=n_down_features,\n",
    "                                           n_causal=n_causal,\n",
    "                                           n_hidden=5,\n",
    "                                           n_latent=5,\n",
    "                                           noise_scale=noise_scale,\n",
    "                                           causal_strength=causal_strength,\n",
    "                                           is_linear=is_linear)\n",
    "        adata_dict[i] = adata\n",
    "        model_res = run_model(adata, max_epochs)\n",
    "        ml_res = run_ml_methods(adata)\n",
    "        model_res_all.append(model_res['weight_value'])\n",
    "        svm_result.append(ml_res['SVM'])\n",
    "        rf_result.append(ml_res['Random Forest'])\n",
    "        lasso_result.append(ml_res['LASSO'])\n",
    "        mi_result.append(ml_res['Mutual Information'])\n",
    "        lr_result.append(ml_res['Logistic Regression'])\n",
    "        pearson_result.append(ml_res['Pearson Correlation'])\n",
    "        anova_result.append(ml_res['ANOVA'])\n",
    "        pc_result.append(ml_res['PC Algorithm'])\n",
    "        vae_grad_result.append(ml_res['VAE_Grad'])\n",
    "    result_dict = {}\n",
    "    result_dict['CauTrigger'] = model_res_all\n",
    "    result_dict['SVM'] = svm_result\n",
    "    result_dict['RF'] = rf_result\n",
    "    result_dict['MI'] = mi_result\n",
    "    result_dict['LR'] = lr_result\n",
    "    result_dict['LASSO'] = lasso_result\n",
    "    result_dict['ANOVA'] = anova_result\n",
    "    result_dict['PCC'] = pearson_result\n",
    "    result_dict['PC'] = pc_result\n",
    "    result_dict['VAE_Grad'] = vae_grad_result\n",
    "    if topk:\n",
    "        subfolder_name = f\"{resdir}/noise_{noise_scale}_causal_{causal_strength}_topk_{topk}\"\n",
    "    else:\n",
    "        subfolder_name = f\"{resdir}/noise_{noise_scale}_causal_{causal_strength}_threshold_{threshold}\"\n",
    "    os.makedirs(subfolder_name, exist_ok=True)\n",
    "    result_dict_df = pd.concat({k + '-' + str(i + 1): v[i] for k, v in result_dict.items() for i in range(len(v))}, axis=1)\n",
    "    result_dict_df_predlabel = select_features(result_dict_df, threshold, topk)\n",
    "    result_dict_df.to_csv(os.path.join(subfolder_name, 'result_weight.csv'))\n",
    "    result_dict_df_predlabel.to_csv(os.path.join(subfolder_name, 'result_label.csv'))\n",
    "    auroc_df = pd.DataFrame()\n",
    "    aupr_df = pd.DataFrame()\n",
    "    acc_df = pd.DataFrame()\n",
    "    mcc_df = pd.DataFrame()\n",
    "    precision_df = pd.DataFrame()\n",
    "    specificity_df = pd.DataFrame()\n",
    "    recall_df = pd.DataFrame()\n",
    "    f1_df = pd.DataFrame()\n",
    "    candidate_num_df = pd.DataFrame()\n",
    "    n = len(next(iter(result_dict.values())))\n",
    "    plt_row = int(np.ceil(n / 4))\n",
    "    for i, (key, value) in enumerate(result_dict.items()):\n",
    "        auroc_list = []\n",
    "        aupr_list = []\n",
    "        acc_list = []\n",
    "        mcc_list = []\n",
    "        precision_list = []\n",
    "        specificity_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        candidate_num_list = []\n",
    "        for j, df in enumerate(value):\n",
    "            df = pd.DataFrame({'weight': df})\n",
    "            df['pred_label'] = select_features(df, threshold, topk)\n",
    "            true_label = np.repeat([1, 0], [n_causal, n_up_features - n_causal])\n",
    "            model_score = df['weight'].values\n",
    "            pred_label = df['pred_label'].values\n",
    "            # AUROC\n",
    "            fpr, tpr, _1 = roc_curve(true_label, model_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            auroc_list.append(roc_auc)\n",
    "            # AUPR\n",
    "            precision, recall, _ = precision_recall_curve(true_label, model_score)\n",
    "            aupr = auc(recall, precision)\n",
    "            aupr_list.append(aupr)\n",
    "            # ACC (TP+TN)/(TP+TN+FP+FN)\n",
    "            acc = accuracy_score(true_label, pred_label)\n",
    "            acc_list.append(acc)\n",
    "            # MCC (TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "            mcc = matthews_corrcoef(true_label, pred_label)\n",
    "            mcc_list.append(mcc)\n",
    "            # Precision TP/(TP+FP)\n",
    "            precision = precision_score(true_label, pred_label, pos_label=1)\n",
    "            precision_list.append(precision)\n",
    "            # Specificity TN/(TN+FP)\n",
    "            cm = confusion_matrix(true_label, pred_label)\n",
    "            TN = cm[0, 0]\n",
    "            FP = cm[0, 1]\n",
    "            specificity = TN / (TN + FP)\n",
    "            specificity_list.append(specificity)\n",
    "            # Recall TP/(TP+FN)\n",
    "            recall = recall_score(true_label, pred_label, pos_label=1)\n",
    "            recall_list.append(recall)\n",
    "            # F1_score 2 * precision * recall / (precision + recall)\n",
    "            f1 = f1_score(true_label, pred_label, pos_label=1)\n",
    "            f1_list.append(f1)\n",
    "            # Candidate TF num\n",
    "            candidate_num = pred_label.sum()\n",
    "            candidate_num_list.append(candidate_num)\n",
    "        auroc_df[f'{key}'] = auroc_list\n",
    "        aupr_df[f'{key}'] = aupr_list\n",
    "        acc_df[f'{key}'] = acc_list\n",
    "        mcc_df[f'{key}'] = mcc_list\n",
    "        precision_df[f'{key}'] = precision_list\n",
    "        specificity_df[f'{key}'] = specificity_list\n",
    "        recall_df[f'{key}'] = recall_list\n",
    "        f1_df[f'{key}'] = f1_list\n",
    "        candidate_num_df[f'{key}'] = candidate_num_list\n",
    "    auroc_df = generate_boxplot_csv(auroc_df, 'AUROC', subfolder_name=subfolder_name)\n",
    "    aupr_df = generate_boxplot_csv(aupr_df, 'AUPR', subfolder_name=subfolder_name)\n",
    "    acc_df = generate_boxplot_csv(acc_df, 'ACC', subfolder_name=subfolder_name)\n",
    "    mcc_df = generate_boxplot_csv(mcc_df, 'MCC', subfolder_name=subfolder_name)\n",
    "    precision_df = generate_boxplot_csv(precision_df, 'Precision', subfolder_name=subfolder_name)\n",
    "    specificity_df = generate_boxplot_csv(specificity_df, 'Specificity', subfolder_name=subfolder_name)\n",
    "    recall_df = generate_boxplot_csv(recall_df, 'Recall', subfolder_name=subfolder_name)\n",
    "    f1_df = generate_boxplot_csv(f1_df, \"F1_score\", subfolder_name=subfolder_name)\n",
    "    candidate_num_df = generate_boxplot_csv(candidate_num_df, \"Candidate_num\", subfolder_name=subfolder_name,\n",
    "                                            set_ylim=False)\n",
    "    score_dict = {\n",
    "        'AUROC': auroc_df,\n",
    "        'AUPR': aupr_df,\n",
    "        'ACC': acc_df,\n",
    "        'MCC': mcc_df,\n",
    "        'Precision': precision_df,\n",
    "        'Specificity': specificity_df,\n",
    "        'Recall': recall_df,\n",
    "        'F1_score': f1_df,\n",
    "        'Candidate_num': candidate_num_df,\n",
    "    }\n",
    "\n",
    "    return score_dict, adata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094414e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T06:14:29.824438Z",
     "start_time": "2023-12-05T06:14:29.757967Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def benchmark_main(noises, causal_strengths, n_samples, n_dataset, threshold, topk, max_epochs,\n",
    "                   n_up_features, n_causal, n_down_features, resdir, is_linear):\n",
    "    benchmark_results = []\n",
    "    adata_dict_all = {}\n",
    "    for i, noise in enumerate(noises):\n",
    "        for j, causal_strength in enumerate(causal_strengths):\n",
    "            result, adata_dict = run_benchmark(n_dataset=n_dataset, n_samples=n_samples, max_epochs=max_epochs, threshold=threshold,\n",
    "                                   topk=topk, noise_scale=noise,\n",
    "                                   n_up_features=n_up_features, n_causal=n_causal,\n",
    "                                   n_down_features=n_down_features,\n",
    "                                   causal_strength=causal_strength, resdir=resdir, is_linear=is_linear)\n",
    "            benchmark_results.append(result)\n",
    "            adata_dict_all[(noise, causal_strength)] = adata_dict\n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'pdf.fonttype': 42,\n",
    "        'ps.fonttype': 42,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 14,\n",
    "        'legend.fontsize': 12,\n",
    "        'xtick.labelsize': 12,\n",
    "        'ytick.labelsize': 12,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'axes.linewidth': 1.2,\n",
    "        'grid.linewidth': 0.5,\n",
    "        'font.sans-serif': ['Arial'],\n",
    "        'font.family': 'sans-serif'\n",
    "    })\n",
    "    \n",
    "    metrics_list = ['AUROC', 'AUPR', 'ACC', 'MCC', 'Precision', 'Specificity', 'Recall', 'F1_score']\n",
    "    for metric in metrics_list:\n",
    "        fig, axs = plt.subplots(len(noises), len(causal_strengths),\n",
    "                                figsize=(len(causal_strengths) * 5, len(noises) * 5))\n",
    "        if len(noises) == 1 and len(causal_strengths) == 1:\n",
    "            axs = np.array([[axs]])\n",
    "        elif len(noises) == 1 or len(causal_strengths) == 1:\n",
    "            axs = np.expand_dims(axs, axis=0) if len(noises) == 1 else np.expand_dims(axs, axis=1)\n",
    "        if metric != 'Candidate_num':\n",
    "            for ax_row in axs:\n",
    "                for ax in ax_row:\n",
    "                    ax.set_ylim(0, 1)\n",
    "        for i, res in enumerate(benchmark_results):\n",
    "            x, y = divmod(i, len(causal_strengths))\n",
    "            sns.boxplot(data=res[f'{metric}'].iloc[:, :n_dataset].T, ax=axs[x, y], palette='Set2')\n",
    "            plt.setp(axs[x, y].get_xticklabels(), rotation=45, ha='right')\n",
    "            axs[x, y].set_title(f'noise: {noises[x]} & causal strength: {causal_strengths[y] * 0.1}')\n",
    "\n",
    "        plt.suptitle(f\"{metric}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{resdir}/{metric}_multi_boxplot.pdf', format='pdf')\n",
    "        plt.savefig(f'{resdir}/{metric}_multi_boxplot.png', format='png')\n",
    "        plt.close()\n",
    "\n",
    "    def create_mean_radar_chart(benchmark_results, metrics_list, resdir):\n",
    "        method_names = ['CauTrigger', 'SVM', 'RF', 'MI', 'LR', 'LASSO', 'ANOVA', 'PCC', 'PC', 'VAE_Grad']\n",
    "        mean_values = {method: [] for method in method_names}\n",
    "    \n",
    "        for metric in metrics_list:\n",
    "            if metric == \"Candidate_num\":\n",
    "                continue\n",
    "            print(f\"Processing metric: {metric}\")\n",
    "            for method_name in method_names:\n",
    "                all_values = []\n",
    "                for res in benchmark_results:\n",
    "                    value = res[metric].loc[method_name, 'Mean']\n",
    "                    all_values.append(value)\n",
    "                mean_val = np.mean(all_values)\n",
    "                mean_values[method_name].append(mean_val)\n",
    "    \n",
    "        categories = [metric for metric in metrics_list if metric != \"Candidate_num\"]\n",
    "        num_categories = len(categories)\n",
    "        angles = [n / float(num_categories) * 2 * np.pi for n in range(num_categories)]\n",
    "        angles += angles[:1]\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "        cmap = plt.get_cmap(\"tab20\")\n",
    "        colors = [cmap(i) for i in np.linspace(0, 1, len(method_names))]\n",
    "        for i, method_name in enumerate(method_names):\n",
    "            values = mean_values[method_name]\n",
    "            print(f\"{method_name} values length: {len(values)}, num_categories: {num_categories}\")\n",
    "            if len(values) != num_categories:\n",
    "                print(f\"Skipping {method_name} due to mismatch in number of categories.\")\n",
    "                continue\n",
    "            values += values[:1]\n",
    "            ax.plot(angles, values, linewidth=2, linestyle='solid', label=method_name, color=colors[i])\n",
    "            ax.fill(angles, values, color=colors[i], alpha=0.25)\n",
    "    \n",
    "        ax.set_rlabel_position(0)\n",
    "        ax.yaxis.set_tick_params(labelsize=10)\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories, fontsize=12)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)\n",
    "        plt.savefig(os.path.join(resdir, \"mean_radar_chart.pdf\"), format=\"pdf\", bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(resdir, \"mean_radar_chart.png\"), format=\"png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    create_mean_radar_chart(benchmark_results, metrics_list, resdir)\n",
    "\n",
    "    return benchmark_results, adata_dict_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf535ed-8020-4319-bf13-3b5a45eac3bb",
   "metadata": {},
   "source": [
    "## Run benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237991c-4a03-41a4-af24-0a81988c417b",
   "metadata": {},
   "source": [
    "### Nonlinear scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c9200-4923-4ca6-97af-53ca2ec17cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [0.01, 0.1, 1.0]\n",
    "causal_strengths = [0.1, 0.2, 0.3]\n",
    "topk = 10\n",
    "is_linear = False\n",
    "benchmark_results, adata_dict_all = benchmark_main(\n",
    "    n_samples=200,\n",
    "    n_dataset=3,\n",
    "    threshold=None,\n",
    "    topk=topk,\n",
    "    max_epochs=300,\n",
    "    n_up_features=100,\n",
    "    n_causal=topk,\n",
    "    n_down_features=200,\n",
    "    noises=noises,\n",
    "    causal_strengths=causal_strengths,\n",
    "    resdir=output_path,\n",
    "    is_linear=is_linear,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7de66c-8c7d-405a-a60b-a2cf9b504410",
   "metadata": {},
   "source": [
    "### Linear scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76263017-cfea-4dc9-b66d-0851c99dc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [0.01, 0.1, 1.0]\n",
    "causal_strengths = [0.1, 0.2, 0.3]\n",
    "topk = 10\n",
    "is_linear = True\n",
    "benchmark_results, adata_dict_all = benchmark_main(\n",
    "    n_samples=200,\n",
    "    n_dataset=3,\n",
    "    threshold=None,\n",
    "    topk=topk,\n",
    "    max_epochs=300,\n",
    "    n_up_features=100,\n",
    "    n_causal=topk,\n",
    "    n_down_features=200,\n",
    "    noises=noises,\n",
    "    causal_strengths=causal_strengths,\n",
    "    resdir=output_path,\n",
    "    is_linear=is_linear,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_CT",
   "language": "python",
   "name": "project_ct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
